{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processo de Mineração de Textos\n",
    "\n",
    "Utilizaremos esta area para testarmos alguns algoritmos que nos auxiliarão no desenvolvimento \n",
    "do projeto, onde pretendemos desenvolver alguma maneira de desenvolver strings de busca para\n",
    "revisões sistemáticas da literatura de maneira automatizada, baseando-se em um Quasi-Gold Standard\n",
    "fornecido.\n",
    "\n",
    "#### Identificação do Problema\n",
    "\n",
    "O problema se localiza no âmbito das revisões sistemáticas da literatura e trata-se de obter, a partir de um QGS informado, uma string de busca que resulte um alto recall (retorne o maior número de artigos presentes no QGS) e uma alta precisão (retorne o menor número de ruído possível).\n",
    "\n",
    "#### Pré-Processamento\n",
    "\n",
    "O pré-processamento se inicia na separação dos 10 arquivos presentes no QGS, em formato PDF, utilizados na revisão sistemática do Francisco. Estes estão localizados [aqui](Files-QGS/QGS-pdf). A partir destes arquivos foram realizadas conversões do formato PDF para o formato TXT de maneira manual, uma vez que diversos destes artigos possuem duas colunas ou algumas dificuldades que impedem a utilização de um conversor automático sobre eles. Tais artigos, agora em formato TXT se encontram [aqui](Files-QGS/QGS-txt). A partir destes 10 arquivos em formato TXT, foram aplicadas técnicas de pré-processamento com o intuito de remover informações irrelevantes de tais arquivos. Para isso, foi utilizado a ferramenta PreText2. \n",
    "\n",
    "Este pré-processamento não foi efetuado localmente, uma vez que aparentemente a versão atual do Perl (v5.26.1) não roda o PreText2 de maneira correta. Para solucionarmos isto, utilizamos uma máquina virtual em nuvem que possuia uma versão desatualizada do Perl (v5.20.1), através da plataforma c9, localizada em https://ide.c9.io/leonardofuchs/mestrado-fuchs.\n",
    "\n",
    "Durante o pré-processamento, seguiu-se o molde de configuração apresentado no arquivo [Draft.pdf](Pre-Processing/Instructions) e foi utilizado uma configuração como a apresentada no arquivo [config](Pre-Processing/Config).\n",
    "\n",
    "Observe que as configurações abaixo foram utilizadas:\n",
    "\n",
    "```\n",
    "lang=\"en\"                     # Específica que os textos estão em inglês\n",
    "dir=\"texts\"                   # Específica o diretório que contém a coleção de textos\n",
    "log=\"pretext.log\"             # Específica o nome do arquivo com o log da execução\n",
    "silence=\"off\">                # Específica que o programa irá exibir mensagens durante a execução\n",
    "\n",
    "\n",
    "<number/>                     # Habilita a limpeza de números\n",
    "<html/>                       # Habilita a limpeza de tags HTML \n",
    "<simbols/>                    # Habilita a limpeza de simbolos \n",
    "stoplist dir=”stoplist”       # Específica o diretório que contém os stopfiles\n",
    "<stopfile>ingl.xml</stopfile> # Específica o arquivo stopfile da lingua inglesa\n",
    "<stemming dir=\"steminfo\"/>    # Habilita geração de stems e específica o diretório em que serão armazenados\n",
    "\n",
    "ngram dir=\"ngraminfo\"         # Específica o diretório que conterá as informações do n-grama\n",
    "<gram n=\"1\"/>                 # Habilita um novo n-grama de tamanho n = 1\n",
    "\n",
    "ngramdir=\"ngraminfo\"          # Específica o diretório que conterá as informações do n-grama (Novamente)\n",
    "discover=\"data\"               # Específica o diretório que conterá os arquivos .data e .names\n",
    "graphics=\"graphics\"           # Específica o diretório no qual serão armazenados os arquivos referentes a gráficos\n",
    "taxonomy=\"taxonomy.txt\"       # Específica o nome do arquivo de taxonomias\n",
    "transpose=\"disabled\"          # Habilita a criação da tabela atributo-valor transposta\n",
    "\n",
    "<gram n=\"1\"                   # Específica o valor de n\n",
    "max=\"1000\" min=\"100\"          # São carregados apenas os tokens com frequência absoluta do valor definido.\n",
    "measure=\"tf\" />               # Define a medida que é utilizada para construir a tabela atributo-valor\n",
    "\n",
    "```\n",
    "\n",
    "Tal execução gerou tal o arquivo de log chamado [pretext.log](Pre-Processing/Config), mostrando que foram gerados 45 stems.\n",
    "\n",
    "Os arquivos relevantes desta execução se encontram [aqui](Pre-Processing/Files), onde a pasta [**data**](Pre-Processing/Files/data) possui os arquivos correspondentes a tabela atributo-valor, a pasta [**ngraminfo**](Pre-Processing/Files/ngraminfo) possui os arquivos referentes ao ngram = 1, onde o arquivo \"1Gram.all\" corresponde aos valores somados, enquanto o arquivo \"1Gram.txt\" corresponde a frequência do 1-gram para cada arquivo separadamente. Além disso, na pasta [**steminfo**](Pre-Processing/Files/steminfo) é encontrado os resultados dos stems gerados, onde o arquivo \"stemWdTF.all\" remete aos stems ordenados por frequência enquanto o arquivo \"stemWdST.all\" remete aos stems ordenados por ordem alfabética. Ademais, a pasta [**texts_Maid**](Pre-Processing/Files/texts_Maid) possui os textos dos arquivos após realizada a filtragem das informações irrelevantes.\n",
    "\n",
    "Notou-se a partir dos arquivos de saída fornecidos pelo PreText2 eram um tanto quanto obscuros, principalmente no caso em que o valor de n no n-grama aumentasse. Para tentar amenizar a dificuldade de visualização, criou-se um script nomeado [table.py](Pre-Processing/Files/data) que formatava uma tabela atributo-valor, para que os valores obtidos fossem visualizados de maneira mais objetiva. Tal script gera um arquivo em formato .txt denominado [table.txt](Pre-Processing/Files/data/table.txt) que engloba a tabela atributo-valor resultante.\n",
    "\n",
    "\n",
    "\n",
    "#### Extração de Padrões\n",
    "\n",
    "A primeira tentativa de se extrair padrões se baseou na aplicação da Alocação Latente de Dirichlet (*Latent Dirichlet Allocation*), que consiste em um modelo estatístico gerativo que permite que conjuntos de observações sejam explicados por grupos não observados que argumentam porque algumas partes dos dados são semelhantes. É uma maneira de descobrir automaticamente tópicos de similaridade que certos documentos ou frases possuem. A demonstração da aplicação desta técnica se encontra no arquivo [**LDA.ipynb**](LDA.ipynb), onde são apresentados primeiramente exemplos da técnica sendo utilizada em conjuntos de dados menores, para em seguida executarmos tal técnica no conjunto de documentos pré-processados do QGS, possuindo ou resultado relativamente satisfatório, mesmo que rodando apenas em 1-grama (apriori não conseguiu-se executar o algoritmo em python com mais de 1-grama).\n",
    "\n",
    "#### Pós-Processamentos e Utilização de Conhecimento\n",
    "...\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
