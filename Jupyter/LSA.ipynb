{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Extração de Tópicos com Latent Semantic Analysis (LSA)\n",
    "\n",
    "\n",
    "Exemplos oferecidos pelo próprio scikit-learn no seguinte link:\n",
    "\n",
    "* https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.TruncatedSVD.html\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Novo QGS\n",
    "\n",
    "Iremos adotar a partir de agora um novo QGS, com 52 artigos relacionados a mineração de texto em auxílio à revisões sistemáticas da literatura, encontrados [aqui](Files-QGS/QGS-ia-pdf). Também está disponível uma planilha [aqui](Files-QGS/QGS.ods) com todos os nomes destes arquivos e se estes estão localizados na base de dados Scopus ou não. A principio, utilizaremos um dataset do QGS em formato .txt que possui apenas o título, palavras-chave e o resumo destes artigos, localizado [aqui](Files-QGS/QGS-ia-txt/metadata/).\n",
    "\n",
    "Importante salientar que dos 52 arquivos utilizados como QGS **46** estão presentes na base de dados Scopus (Ao se procurar pelo titulo destes, são encontrados com facilidade).\n",
    "\n",
    "Abaixo segue um código exemplo de como foi acessado tal base e efetuado novamente os testes realizados com o QGS anterior, alterando apenas os valores de number_topics e number_words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 1: {systematic - reviews - review - learning - systematic reviews}\n",
      "\n",
      "Topic 2: {mining - process - text - literature - study}\n",
      "\n",
      "TITLE-ABS-KEY((\"systematic\" AND \"reviews\" AND \"review\" AND \"learning\" AND \"systematic reviews\") OR (\"mining\" AND \"process\" AND \"text\" AND \"literature\" AND \"study\"))\n"
     ]
    }
   ],
   "source": [
    "# encoding: utf-8\n",
    "from __future__ import print_function\n",
    "from time import time\n",
    "from sklearn.datasets import load_files\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.decomposition import NMF, LatentDirichletAllocation\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "number_topics = 2\n",
    "number_words = 5\n",
    "max_document_frequency = 1.0\n",
    "min_document_frequency = 0.4\n",
    "ngram = (1, 3)\n",
    "max_features = None\n",
    "\n",
    "iterations = 5000\n",
    "\n",
    "# Imprime os tópicos com as palavras em ordem\n",
    "def print_top_words(model, feature_names, number_words):\n",
    "    for topic_index, topic in enumerate(model.components_):\n",
    "        message = \"Topic %d: \" % (topic_index + 1)\n",
    "        message += \"{\"\n",
    "        message += \" - \".join([feature_names[i]\n",
    "                               for i in topic.argsort()[:-number_words - 1:-1]])\n",
    "        message += \"}\\n\"\n",
    "        print(message)\n",
    "\n",
    "def print_string(model, feature_names, number_words):\n",
    "    message = (\"TITLE-ABS-KEY(\")\n",
    "    for topic_index, topic in enumerate(model.components_):\n",
    "        message += \"(\\\"\"\n",
    "        message += \"\\\" AND \\\"\".join([feature_names[i]\n",
    "                               for i in topic.argsort()[:-number_words - 1:-1]])\n",
    "        message += \"\\\")\"\n",
    "        if topic_index < number_topics - 1:\n",
    "            message += \" OR \"\n",
    "        else:\n",
    "            message += \"\"\n",
    "    message += \")\"\n",
    "    print(message)\n",
    "\n",
    "\n",
    "# Carrega o dataset de treinamento\n",
    "files = load_files(container_path = '/home/fuchs/Documentos/MESTRADO/Masters/Files-QGS/QGS-ia-txt/metadata', encoding=\"iso-8859-1\")\n",
    "\n",
    "# Usa tf-idf para o NMF.\n",
    "tfidf_vectorizer = TfidfVectorizer(max_df = max_document_frequency,\n",
    "                                   min_df = min_document_frequency,\n",
    "                                   ngram_range= ngram,\n",
    "                                   max_features = max_features,\n",
    "                                   stop_words='english')\n",
    "\n",
    "tfidf = tfidf_vectorizer.fit_transform(files.data)\n",
    "\n",
    "# Salva os nomes das palavras em um dicionário\n",
    "dic = tfidf_vectorizer.get_feature_names()\n",
    "\n",
    "# SVD para reduzir a dimensionalidade\n",
    "svd_model = TruncatedSVD(n_components = number_topics,\n",
    "                         algorithm = 'randomized',\n",
    "                         n_iter = iterations)\n",
    "\n",
    "# Pipeline do tf-idf + SVD, fit e aplicando nos arquivos\n",
    "svd_transformer = Pipeline([('tfidf', tfidf_vectorizer), ('svd', svd_model)])\n",
    "\n",
    "svd_transformer.fit_transform(files.data)\n",
    "\n",
    "# Imprime os (number_topics) tópicos com as (number_words) palavras\n",
    "print_top_words(svd_model, dic, number_words)\n",
    "\n",
    "print_string(svd_model, dic, number_words)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TESTES v.1\n",
    "\n",
    "Iremos testar o algoritmo com a lógica em que o AND fica entre as palavras do mesmo tópico e OR entre os tópicos, realizado sobre a base de dados apenas dos metadados (apenas título, abstract e keywords), uma vez que foi a que retornou os melhores resultados no LDA.\n",
    "\n",
    "-------------------------------------------------\n",
    "\n",
    "### 1° Teste: 2 Tópicos e 5 palavras\n",
    "\n",
    "(Código apresentado abaixo)\n",
    "\n",
    "**Resultado**\n",
    "\n",
    "Topic 1: {systematic - reviews - review - learning - systematic reviews}\n",
    "\n",
    "Topic 2: {mining - process - text - literature - study}\n",
    "\n",
    "String: TITLE-ABS-KEY((\"systematic\" AND \"reviews\" AND \"review\" AND \"learning\" AND \"systematic reviews\") OR (\"mining\" AND \"process\" AND \"text\" AND \"literature\" AND \"study\"))\n",
    "\n",
    "Busca: 4,619 documentos encontrados \n",
    "\n",
    "-------------------------------------------------\n",
    "\n",
    "### 2° Teste: 3 Tópicos e 5 palavras\n",
    "\n",
    "(Código apresentado abaixo)\n",
    "\n",
    "**Resultado**\n",
    "\n",
    "Topic 1: {systematic - reviews - review - learning - systematic reviews}\n",
    "\n",
    "Topic 2: {mining - process - text - literature - study}\n",
    "\n",
    "Topic 3: {study - evidence - evidence based - literature - based}\n",
    "\n",
    "String: TITLE-ABS-KEY((\"systematic\" AND \"reviews\" AND \"review\" AND \"learning\" AND \"systematic reviews\") OR (\"mining\" AND \"process\" AND \"text\" AND \"literature\" AND \"study\") OR (\"study\" AND \"evidence\" AND \"evidence based\" AND \"literature\" AND \"based\"))\n",
    "\n",
    "Busca: 28,073 documentos encontrados"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
