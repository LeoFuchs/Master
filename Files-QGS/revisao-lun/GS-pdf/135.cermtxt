804
IEEE TRANSACTIONS ON AUTOMATIC CONTROL, VOL. 59, NO. 3, MARCH 2014
On the Performance Analysis of Resilient Networked
Control Systems Under Replay Attacks
Minghui Zhu and Sonia Martínez
Abstract-This technical note studies a resilient control problem for discrete-time,
linear time-invariant systems subject to state and input constraints.
State measurements and control commands are transmitted over a
communication network and could be corrupted by adversaries. In particular,
we consider the replay attackers who maliciously repeat the messages
sent from the operator to the actuator. We propose a variation of the receding-horizon
control law to deal with the replay attacks and analyze the
resulting system performance degradation. A class of competitive (resp. cooperative)
resource allocation problems for resilient networked control systems
is also investigated.
Index Terms- Networked control systems, resilient control.
I. INTRODUCTION
The recent advances of information technologies have boosted the
emergence of networked control systems where information networks
are tightly coupled to physical processes and human intervention.
Such sophisticated systems create a wealth of new opportunities at
the expense of increased complexity and system vulnerability. In
particular, malicious attacks in the cyber world are a current practice
and a major concern for the deployment of networked control systems.
Thus, the ability to analyze their consequences becomes of prime
importance in order to enhance the resilience of these new-generation
control systems.
This technical note considers a single-loop remotely-controlled
system, in which the plant, together with a sensor and an actuator,
and the system operator are spatially distributed and connected via
a communication network. In particular, state measurements are
communicated from the sensor to the system operator through the
network; then, the generated control commands are transmitted to the
actuator through the same network. This model is an abstraction of a
variety of existing networked control systems, including supervisory
control and data acquisition (SCADA) networks in critical infrastructures
(e.g., power systems and water management systems) and
remotely piloted unmanned aerial vehicles (UAVs). The objective of
the technical note is to design and analyze resilient controllers against
replay attacks.
Literature Review: Recently, the cyber security of control systems
has received increasing attention. The research effort has been devoted
to studying two aspects: attack detection and attack-resilient control.
Regarding attack detection, a particular class of cyber attacks, namely
false data injection, against state estimation is studied in [26], [29],
[30]. The paper [19] studies the detection of the replay attacks, which
Manuscript received January 17, 2013; revised March 26, 2013; accepted July
12, 2013. Date of publication August 28, 2013; date of current version February
19, 2014. This work was supported by the AFOSR Grant 11RSL548. Recommended
by Associate Editor L. Schenato.
M. Zhu is with the Department of Electrical Engineering, Pennsylvania State
University, University Park, PA 16802 USA (e-mail: muz16@psu.edu).
S. Martínez is with the Department of Mechanical and Aerospace Engineering,
University of California, San Diego, La Jolla CA 92093 USA (e-mail:
soniamd@ucsd.edu).
Color versions of one or more of the figures in this paper are available online
at http://ieeexplore.ieee.org.
Digital Object Identifier 10.1109/TAC.2013.2279896
maliciously repeat transmitted data. In the context of multi-agent systems,
the papers of [25], [28] determine conditions under which consensus
multi-agent systems can detect misbehaving agents. As for attack-resilient
control, the papers [2], [32], [33] are devoted to studying
deception attacks, where attackers intentionally modify measurements
and control commands. Denial-of-service (DoS) attacks destroy the
data availability in control systems and are tackled in recent papers
[1], [3], [4], [9]. More specifically, the papers [1], [9] formulate finite-horizon
LQG control problems as dynamic zero-sum games between
the controller and the jammer. In [3], the authors investigate the
security independency in infinite-horizon LQG against DoS attacks,
and fully characterize the equilibrium of the induced game. In our paper
[35], a distributed receding-horizon control law is proposed to ensure
that vehicles reach the desired formation despite the DoS and replay
attacks.
The problems of control and estimation over unreliable communication
channels have received considerable attention over the last decade
[12]. Key issues include band-limited channels [15], [22], quantization
[6], [21], packet dropout [10], [13], [27], delay [5] and sampling [23].
Receding-horizon networked control is studied in [7], [11], [24] for
package dropouts and in [14], [16] for transmission delays. Package
dropouts and DoS attacks (resp. transmission delays and replay attacks)
cause similar affects to control systems. So the existing recedinghorizon
control approaches exhibit the robustness to certain classes of
DoS and replay attacks under their respective assumptions. However,
none of these papers characterizes the performance degradation of receding-horizon
control induced by the communication unreliability.
Contributions: We study a variation of the receding-horizon control
under the replay attacks. A set of sufficient conditions are provided to
ensure asymptotical and exponential stability. More importantly, we
derive a simple and explicit relation between the infinite-horizon cost
and the computing and attacking horizons. By using such relation, we
characterize a class of competitive (resp. cooperative) resource allocation
problems for resilient networked control systems as convex games
(resp. programs). The preliminary results are published in [33] where
receding-horizon control is used to deal with a class of deception attacks.
The complete version can be found in [36].
II. ATTACK-RESILIENT RECEDING-HORIZON CONTROL
A. Description of the Controlled System
Consider the following discrete-time, linear time-invariant dynamic
system:
where is the system state, and is the system
input at time . The matrices and
represent the state and the input matrix, respectively. States and inputs
of system (1) are constrained to be in some sets; i.e., and
, for all , where and
. The quantities and are running state and input
costs, respectively, for some and positive-definite and symmetric
matrices. We assume the following holds for the system:
Assumption 2.1: (Stabilizability): The pair is stabilizable.
This assumption ensures the existence of such that the spectrum
is strictly inside the unit circle where . In the
remainder of the technical note, will be referred to as the
auxiliary controller. We then impose the following condition on the
constraint sets.
(1)
0018-9286 © 2013 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission.
See http://www.ieee.org/publications_standards/publications/rights/index.html for more information.
IEEE TRANSACTIONS ON AUTOMATIC CONTROL, VOL. 59, NO. 3, MARCH 2014
805
and
Assumption 2.2: (Constraint sets): The sets
for .
and
are convex
B. The Closed-Loop System With the Replay Attacker
System (1) together with the sensor and the actuator are spatially
separated from the operator. These entities are connected through communication
channels. In the network, there is a replay attacker who maliciously
repeats the messages delivered from the operator to the actuator.
In particular, the adversary is associated with a memory whose
state is denoted by . If a replay attack is launched at time , the
adversary executes the following: (i) erases the data sent from the operator;
(ii) sends previous data stored in her memory, , to the actuator;
(iii) maintains the state of the memory; i.e., .
In this case, we use to indicate the occurrence of a replay
attack. If the attacker keeps idle at time , then data is intercepted,
say , sent from the operator to plant, and stored in memory; i.e.,
. In this case, and is successfully received
by the actuator. Without loss of any generality, we assume that
.
We now define the variable with initial state
to indicate the consecutive number of the replay attacks. If ,
then ; otherwise, . So, the quantity
represents the number of consecutive attacks up to time .
A replay attack requires spending certain amount of energy. We assume
that the energy of the adversary is limited, and the adversary is
only able to launch at most consecutive attacks. This assumption
is formalized as follows:
Assumption 2.3: (Maximum number of consecutive attacks): There
is an integer such that .
Replay attacks have been successfully used by the virus attack
of Stuxnet [8], [18]. This class of attacks can be easily detected by
attaching a time stamp to each control command. In the remainder of
the technical note, we assume that the attacks can always be detected
and focus on the design and analysis of resilient controllers against
them.
C. Attack-Resilient Receding-Horizon Control Law
Here we propose attack-resilient receding-horizon control law,
(for short, AR-RHC), a variation of the receding-horizon control in; e.g.
[16], [17], to deal with the replay attacks. AR-RHC is formally stated
in Algorithm 1. In particular, at each time instant, the plant stores the
computed control sequence which will be used in response to replay
attacks in the near future. The terminal state cost is chosen to coincide
with the running state cost. This is instrumental for analyzing the
Lyapunov function in terms of the computing horizon and further the
performance degradation in Theorem 2.1.
Algorithm 1 The attack-resilient receding-horizon control law
Initialization: The following steps are first performed by the operator:
is strictly inside the unit circle.
and obtain
by solving the following
1: Choose
so that
2: Choose
Lyapunov equation:
(2)
3: Choose a constant
.
such that
Fig. 1. Closed-loop system with attacks from the operator to the actuator.
Iteration: At each
the following steps:
, the operator, actuator and sensor execute
1: The operator solves the following
namely -QP, parameterized by
-horizon quadratic program,
:
obtains the solution
sends it to the actuator.
2: If
implements
If
, the actuator receives
, and the sensor sends
, the actuator implements
, and the sensor sends
, sets
3: Repeat for
.
, and
,
to the operator.
in , sets
to the operator.
In what follows, we present the results characterizing the stability
and infinite-horizon cost induced by AR-RHC. See Table I, for the main
notations employed. Notice that the following property holds:
where and are defined in Table I. On the other hand, for in
Table I, as , and is strictly increasing in
and upper bounded by . Then, given any integer , there is a
smallest integer such that for all , it holds
that
Analogously, given any integer
such that for all
, there is a smallest integer
, it holds that
806
IEEE TRANSACTIONS ON AUTOMATIC CONTROL, VOL. 59, NO. 3, MARCH 2014
TABLE I
MAIN NOTATIONS USED IN THE FOLLOWING SECTIONS
One can easily verify . The following theorem characterizes
the stability and infinite-horizon cost of system (1) under
AR-RHC where represents the value of the -QP parameterized
by .
Theorem 2.1: (Stability and Infinite-Horizon Cost): Let Assumptions
2.1, 2.2 and 2.3 hold.
1) (Exponential stability) Suppose .
Then system (1) under AR-RHC is exponentially stable
when starting from with a rate of in the sense that
. In addition, the infinite-horizon
cost of system (1) under AR-RHC is bounded above
by .
2) (Asymptotic stability) If , then
system (1) under AR-RHC is asymptotically stable when starting
from .
III. DISCUSSION AND SIMULATIONS
A. Extensions
AR-RHC with Theorem 2.1 can be readily extended to several scenarios,
including DoS attacks, measurement attacks and the combinations
of such attacks. If the adversary launches a DoS attack on control
commands, the actuator receives nothing and then performs Step 3 in
AR-RHC. The adversary may produce the replay attacks on the measurements
sent from the sensor to the operator. If this happens, then
the operator does not send anything to the actuator and the actuator
performs Step 3 in AR-RHC.
B. Explicit Upper Bounds on
and
Consider
and let
and
. Note that
So it suffices to find such that
equivalent to the following:
. The relation
(3)
is
Hence, an explicit upper bound on
.
We now move to find an explicit upper bound on
is
. Note that
So, an explicit upper bound on is
. This pair of upper bounds
clearly demonstrate that a higher computational complexity; i.e., a
larger , is caused by a larger , indicating that the adversary is less
energy constrained. On the other hand, the second term in
approaches a constant as goes to infinity. So can be upper
bounded by an affine function. However, the second term in
dominates when is large. So exponential stability demands a much
higher cost than asymptotic stability when is large.
C. A Reverse Scenario
Reciprocally, for any horizon , there is a largest integer
(resp. ) such that for all
(resp. ), it holds that (resp. ). Theorem
2.1 still applies to this reverse scenario and characterizes the “security
level” or “amount of resilience” that the proposed receding-horizon
control algorithm possesses.
D. Optimal Resilience Management
The analysis of Theorem 2.1 quantifies the cost and constraints that
allow the AR-RHC algorithm to work despite consecutive attacks
under limited computation capabilities. These metrics can be used for
optimal resilience management of a network as follows.
IEEE TRANSACTIONS ON AUTOMATIC CONTROL, VOL. 59, NO. 3, MARCH 2014
807
As [3], we consider a set of players where the
players share a communication network and each of them is associated
with a decoupled dynamic system
Each player uses his own AR-RHC with horizon . The notations
in the previous sections can be defined analogously for each player and
the notations of player will be indexed by .
By (3), we associate player with the following cost function:
where is the security investment of
player , is a weight on the security cost the and is the
vector with ones. The non-negative real value represents
the security level given the investment vector of all players, where
is convex, non-decreasing, and smooth. We assume
that each player has a fixed computational power, and so is fixed.
The players need to make the investment such that
Remark 3.1: Note that is an integer in (3). In (5) and (6), we use
the real value of as an approximation.
We now compute the first-order partial derivative of as follows:
(4)
(5)
(6)
where we use the shorthand . Recall that and is
non-decreasing and convex. We further derive the second-order partial
derivative and is convex in . Analogously, one
can show that is convex in .
1) Competitive Resource Allocation Scenario: Consider a resilience
management game, where each player minimizes his cost
, subject to the common constraint (6) and his private constraint
. Since and are convex in ,
then the game is a generalized convex game. The distributed algorithms
in [31] can be directly utilized to numerically compute a Nash
equilibrium of the resilience management game, and the algorithms in
[31] are able to tolerate transmission delays and packet dropouts.
Remark 3.2: The paper [3] considers a set of identical and independent
networked control systems and each of them aims to solve an
infinite-horizon LQG problem. The authors study a different security
game where the decisions of each player are binary, participating in the
security investment or not.
2) Cooperative Resource Allocation Scenario: Consider a resilience
management optimization problem, where the players aim to
collectively minimize , subject to the global constraint
(6) and the private constraint . Since
and are convex, then the problem is a convex program. The
distributed algorithms in [34] can be directly exploited to numerically
compute a global minimizer of this problem, and the algorithms in
[34] are robust to the dynamic changes of inter-player topologies.
E. Simulations
In this section, we provide a numerical example to illustrate the performance
of our algorithm. The set of system parameters are given as
follows:
Fig. 2. Trajectories of under the attack-resilient receding-horizon
control algorithm for different values of .
Fig. 2 shows the temporal evolution of under three attacking
horizons , 2, 5. One can see that a larger induces
a longer time to converge, and larger oscillation before reaching the
equilibrium. In our simulations, a smaller horizon than the
one determined theoretically is already sufficient to achieve system
stabilization.
IV. CONCLUSIONS
In this technical note, we have studied a resilient control problem
where a linear dynamic system is subject to the replay and DoS attacks.
We have proposed a variation of the receding-horizon control law for
the operator and analyzed system stability and performance degradation.
We have also studied a class of competitive (resp. cooperative)
resource allocation problems for resilient networked control systems.
Extensions to multi-agent systems will be considered in the future.
REFERENCES
[1] S. Amin, A. Cardenas, and S. S. Sastry, “Safe and secure networked
control systems under denial-of-service attacks,” in Hybrid Systems:
Computation and Control. Stockholm, Sweden: Springer, 2009, pp.
31-45.
[2] S. Amin, X. Litrico, S. S. Sastry, and A. M. Bayen, “Stealthy deception
attacks on water SCADA systems,” in Hybrid Systems: Computation
and Control. Stockholm, Sweden: Springer, 2010, pp. 161-170.
[3] S. Amin, G. A. Schwartz, and S. S. Sastry, “Security of interdependent
and identical networked control systems,” Automatica, vol. 49,
pp. 186-192, 2013.
[4] G. K. Befekadu, V. Gupta, and P. J. Antsaklis, “Risk-sensitive control
under a class of denial-of-service attack models,” in Proc. American
Control Conf., San Francisco, CA, Jun. 2011, pp. 643-648.
[5] M. S. Branicky, S. M. Phillips, and W. Zhang, “Stability of networked
control systems: Explicit analysis of delay,” in Proc. American Control
Conf., Chicago, IL, 2000, pp. 2352-2357.
[6] R. W. Brockett and D. Liberzon, “Quantized feedback stabilization
of linear systems,” IEEE Trans. Autom. Control, vol. 45, no. 7, pp.
1279-1289, Jul. 2000.
[7] B. Ding, “Stabilization of linear systems over networks with bounded
packet loss and its use in model predictive control,” Automatica, vol.
47, no. 9, pp. 2526-2533, Oct. 2011.
[8] N. Falliere, L. O. Murchu, and E. Chien, W32.Stuxnet Dossier
Symantec Corporation, 2011.
[9] A. Gupta, C. Langbort, and T. Basar, “Optimal control in the presence
of an intelligent jammer with limited actions,” in Proc. IEEE Int. Conf.
Decision and Control, Atlanta, GA, Dec. 2010, pp. 1096-1101.
808
IEEE TRANSACTIONS ON AUTOMATIC CONTROL, VOL. 59, NO. 3, MARCH 2014
[10] V. Gupta and N. Martins, “On stability in the presence of analog erasure
channels between controller and actuator,” IEEE Trans. Autom.
Control, vol. 55, no. 1, pp. 175-179, Jan. 2010.
[11] V. Gupta, B. Sinopoli, S. Adlakha, and A. Goldsmith, “Receding
horizon networked control,” in Proc. Allerton Conf. Communications,
Control and Computing, Urbana-Champaign, IL, Sep. 2006.
[12] J. Hespanha, P. Naghshtabrizi, and Y. Xu, “A survey of recent results in
networked control systems,” Proc. IEEE Special Issue on Technology
of Networked Control Systems, vol. 95, no. 1, pp. 138-162, 2007.
[13] O. C. Imer, S. Yuksel, and T. Basar, “Optimal control of LTI systems
over communication networks,” Automatica, vol. 42, no. 9, pp.
1429-1440, 2006.
[14] K. Kobayashi and K. Hiraishi, “Self-triggered model predictive control
with delay compensation for networked control systems,” in Acies,
2012, pp. 3200-3205.
[15] D. Liberzon and J. P. Hespanha, “Stabilization of nonlinear systems
with limited information feedback,” IEEE Trans. Autom. Control, vol.
50, no. 6, pp. 910-915, Jun. 2005.
[16] G. P. Liu, J. X. Mu, D. Rees, and S. C. Chai, “Design and stability
analysis of networked control systems with random communication
time delay using the modified MPC,” Int. J. Control, vol. 79, no. 4,
pp. 288-297, Apr. 2006.
[17] D. Q. Mayne, J. B. Rawlings, C. V. Rao, and P. O. M. Scokaert,
“Constrained model predictive control: Stability and optimality,”
Automatica, vol. 36, pp. 789-814, 2000.
[18] Y. Mo, T. Kim, K. Brancik, D. Dickinson, L. Heejo, A. Perrig, and
B. Sinopoli, “Cyber-physical security of a smart grid infrastructure,”
Proc. IEEE, vol. 100, no. 195-209, p. 215, 2012.
[19] Y. Mo and B. Sinopoli, “Secure control against replay attacks,” in
Allerton Conf. on Communications, Control and Computing, UrbanaChampaign,
IL, Sep. 2009.
[20] T. Mori, N. Fukuma, and M. Kuwahara, “Upper and lower bounds for
the solution to the discrete Lyapunov matrix equation,” Int. J. Control,
vol. 36, pp. 889-892, 1982.
[21] G. N. Nair, R. J. Evans, I. M. Y. Mareels, and W. Moran, “Topological
feedback entropy and nonlinear stabilization,” IEEE Trans. Autom.
Control, vol. 49, no. 9, pp. 1585-1597, Sep. 2004.
[22] G. N. Nair, F. Fagnani, S. Zampieri, and R. J. Evans, “Feedback control
under data rate constraints: An overview,” Proc. IEEE (Special Issue on
Technology of Networked Control Systems), vol. 95, no. 1, pp. 108-137,
2007.
[23] D. Nesic and A. Teel, “Input-output stability properties of networked
control systems,” IEEE Trans. Autom. Control, vol. 49, no. 10, pp.
1650-1667, Oct. 2004.
[24] D. Mu noz de la Peña and P. D. Christofides, “Lyapunov-based model
predictive control of nonlinear systems subject to data losses,” IEEE
Trans. Autom. Control, vol. 53, no. 9, pp. 2076-2089, Sep.. 2008.
[25] F. Pasqualetti, A. Bicchi, and F. Bullo, “Consensus computation in unreliable
networks: A system theoretic approach,” IEEE Trans. Autom.
Control, vol. 57, no. 1, pp. 90-104, Jan. 2012.
[26] F. Pasqualetti, R. Carli, and F. Bullo, “A distributed method for state
estimation and false data detection in power networks,” in Proc. IEEE
Int. Conf. Smart Grid Communications, Oct. 2011, pp. 469-474.
[27] L. Schenato, B. Sinopoli, M. Franceschetti, K. Poolla, and S. S. Sastry,
“Foundations of control and estimation over lossy networks,” Proc.
IEEE (Special Issue on Technology of Networked Control Systems),
vol. 95, no. 1, pp. 163-187, 2007.
[28] S. Sundaram and C. N. Hadjicostis, “Distributed function calculation
via linear iterative strategies in the presence of malicious agents,” IEEE
Trans. Autom. Control, vol. 56, no. 7, pp. 1731-1742, Jul. 2011.
[29] A. Teixeira, S. Amin, H. Sandberg, K. H. Johansson, and S. S. Sastry,
“Cyber security analysis of state estimators in electric power systems,”
in Proc. IEEE Int. Conf. Decision and Control, Atlanta, GA, Dec. 2010,
pp. 5991-5998.
[30] L. Xie, Y. Mo, and B. Sinopoli, “False data injection attacks in electricity
markets,” in Proc. IEEE Int. Conf. on Smart Grid Communications,
Gaithersburg, MD, Oct. 2010, pp. 226-231.
[31] M. Zhu and E. Frazzoli, “On distributed equilibrium seeking for generalized
convex games,” in Proc. IEEE Int. Conf. Decision and Control,
Maui, HI, Dec. 2012.
[32] M. Zhu and S. Martínez, “Attack-resilient distributed formation control
via online adaptation,” in IEEE Int. Conf. on Decision and Control,
Orlando, FL, Dec. 2011, pp. 6624-6629.
[33] M. Zhu and S. Martínez, “Stackelberg game analysis of correlated attacks
in cyber-physical system,” in Proc. American Control Conf., Jun.
2011, pp. 4063-4068.
[34] M. Zhu and S. Martínez, “On distributed convex optimization under inequality
and equality constraints via primal-dual subgradient methods,”
IEEE Trans. Autom. Control, vol. 57, no. 1, pp. 151-164, Jan. 2012.
[35] M. Zhu and S. Martínez, “On distributed resilient consensus against replay
attacks in adversarial networks,” in Proc. American Control Conf.,
Montreal, QC, Canada, Jun. 2012, pp. 3553-3558.
[36] M. Zhu and S. Martínez, “On the performance analysis of resilient networked
control systems under replay attack,” 2013. [Online]. Available:
http://arxiv.org/abs/1307.2790
Adaptive Failure Compensation Control for Uncertain
Systems With Stochastic Actuator Failures
Huijin Fan, Bing Liu, Yindong Shen, and Wei Wang
Abstract-In this technical note, an adaptive failure compensation
problem has been studied for a class of nonlinear uncertain systems
subject to stochastic actuator failures and unknown parameters. The
stochastic functions related to Markovian variables have been introduced
to denote the failure scaling factors for each actuators which is much
more practical and challenging. Firstly, by taking into account of the
Markovian variables existing in the system, some preliminary knowledges
have been established. Then, by employing backstepping strategy, an
adaptive failure compensation control scheme has been proposed, which
ensures the boundedness in probability of all the closed-loop signals in the
presence of stochastic actuator failures. A simulation example is presented
to show the effectiveness of the proposed scheme.
Index Terms-Adaptive control, backstepping, failure compensation,
Markovian variables, stochastic actuator failures.
I. INTRODUCTION
Actuator failure is usually encountered in practical systems [1]-[4],
i.e., flight control systems, networked control systems and so on. Such
unexpected actuator failure may degrade the system performance,
render the instability of the closed-loop system, or even worse, lead
to catastrophic accidents. To increase system reliability and security,
it is significantly important to design failure compensation scheme,
which compensates the actuator failure and maintains the performance
of the closed-loop system. Different actuator failure compensation
approaches have been proposed in literatures; see, for example, multiple-mode
designs [5], fault detection and diagnosis-based designs [6],
eigenstructure assignment [7], sliding mode control-based scheme [8]
and adaptive methods [9]-[13]. Among which, adaptive-based failure
Manuscript received August 31, 2012; revised March 07, 2013 and July 23,
2013; accepted October 15, 2013. Date of publication October 24, 2013; date
of current version February 19, 2014. This work was supported by the National
Natural Science Foundation of China under Grants 61174079, 61034006,
61203081, and 61203068. Recommended by Associate Editor P. Shi.
H. Fan is with the Key Laboratory of Image Processing and Intelligent Control,
School of Automation, Huazhong University of Science and Technology,
Wuhan 430074, China (e-mail: ehjfan@mail.hust.edu.cn).
B. Liu and Y. Shen are with the Key Laboratory of Image Processing and
Intelligent Control, School of Automation, Huazhong University of Science
and Technology, Wuhan 430074, China (e-mail: lbhust621@126.com; yindong@mail.hust.edu.cn).
W. Wang is with Department of Automation, Tsinghua University, Beijing
100084, China (e-mail: wwang28@tsinghua.edu.cn).
Color versions of one or more of the figures in this paper are available online
at http://ieeexplore.ieee.org.
Digital Object Identifier 10.1109/TAC.2013.2287115
0018-9286 © 2013 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission.
See http://www.ieee.org/publications_standards/publications/rights/index.html for more information.