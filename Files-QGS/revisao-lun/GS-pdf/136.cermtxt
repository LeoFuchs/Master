Quanayn Zuh and
Tarme Ba¸asr
Digital Object Identifier 10.1109/MCS.2014.2364710
Date of publication: 19 January 2015
46 IEEE CONTROL SYSTEMS MAGAZINE » FEBRUARY 2015
Game-Theoretic
Methods
for Robustness,
Security, and
Resilience of
Cyberphysical
Control Systems
Games-in-Games
PrinciP le for oP
timal
c ross- l ayer r
c ontrol s
esilient
ystems
Ction systems, are increasingly
ritical infrastructures, such as
power grids and transportausing
open networks for operation.
The use of open networks
poses many challenges for control systems.
The classical design of control
systems takes into account modeling
uncertainties as well as physical disturbances,
providing a multitude of
control design methods such as robust
control, adaptive control, and stochastic
control. With the growing level of
integration of control systems with new
information technologies, modern control systems face uncertainties
not only from the physical world but also from
the cybercomponents of the system. The vulnerabilities
of the software deployed in the new control system infrastructure
will expose the control system to many potential
1066-033X/15©2015ei
t able 1 a summary of notation.
s ymbol
meaning
c(t,x,u;i)
Instantaneous cost function
x(t)
x0
i(t)
u(t)
n
w(t)
qf
q0
o
mij
A
L
f(k)
g(k)
J(u,w)
Vi (t,x)
vb(i,f,g)
v*b(i)
c*CL
State of physical system
Initial state of physical system
State of cybersystem
Control input to the physical system
Closed-loop control strategy
Disturbance input to the physical system
Terminal cost function
Cost function for initial condition
Closed-loop strategy of disturbance
Transition rate from state i to state j
Action space of the attacker
Action space of the defender
Mixed strategy of the defender at time k
Mixed strategy of the attacker at time k
Expected cost for the physical system
performance
Value function associated with the HJI equation
Payoff for the cybersystem performance
Value function associated with Shapley's
optimality equation
Optimal attenuation level under closed-loop
control strategies
risks and threats from attackers. Exploitation of these vulnerabilities
can lead to severe damage as has been reported
in various news outlets [1], [2]. More recently, it has been
reported in [3] and [4] that a computer worm, Stuxnet, was
spread to target Siemens supervisory control and data acquisition
(SCADA) systems that are congfiured to control
and monitor specicfi industrial processes.
Uncertainties from the cybersystem are often unanticipated
and more catastrophic for control systems in terms of
their high impact and low effort as compared to those from
the physical world. It is imperative to consider the cyber
uncertainties in addition to the physical ones in the controller
design. Those uncertainties can be caused by intentional
malicious behaviors and/or by rare events, such as severe
weather or natural disasters. Engineers are accustomed to
designing systems to be reliable and robust, despite noise
and disturbances. However, the cybersecurity aspect of
control systems has posed new challenges for engineers
and system designers.
The notion of robustness often refers to a system's ability
to withstand a known range of uncertain parameters or
disturbances, whereas security describes the system's ability
to withstand and be protected from malicious behaviors
and unanticipated events. These two system properties are
pre-event concepts, that is, the system is designed to be
robust or secure offline before it is perturbed or attacked.
Despite many engineering efforts toward designing robust
and secure systems, it is costly and impractical, if not
impossible, to achieve perfect robustness and security
against all possible attacks and events. This fact, however,
renders it essential to investigate the resilience aspect of a
system, which refers to the system's ability to recover online
after adversarial events occur. It is a post-event concept.
Hence, to provide performance guarantees, control systems
should be designed to be inherently resilient, allowing
them to self-recover from unexpected attacks and failures.
Resilience has been studied in many fields such as psychology
[5], ecology [6], and organizational behavior [7].
The concept has also appeared in various engineering
fields, such as aviation, nuclear power, oil and gas, transportation,
emergency health care, and communication networks
[8], [9]. The literature on resilience engineering is
often found to be very diverse, qualitative, and area specific.
References [10] and [11] propose the concept of resilient control
systems, which emphasizes designing control systems
for operation in an adversarial and uncertain environment.
Resilient control systems are required to be capable of maintaining
the state awareness of threats and anomalies and
assuring an accepted level of operational normalcy in
response to disturbances, including threats of an unexpected
and malicious nature. Traditional concepts of robustness,
reliability, and cybersecurity appear to be insufficient
to address these emerging issues of control systems.
Metrics for robustness in control systems have been well
studied in the literature [12], [13]. A game-theoretic
approach has been introduced to obtain the H3 optimal,
disturbance-attenuating minimax controllers by viewing
the controller as the cost minimizer and the disturbance as
the maximizer. Likewise, cybersecurity problems have
been studied using game theory [14], which provides a natural
framework for capturing the conflict of goals between
an attacker who seeks to maximize the damage inflicted on
the system and a defender who aims to minimize it. Moreover,
the design of security strategies is enabled by many
existing analytical and computational tools [15]. Many metrics
for the resilience of control systems have been proposed
recently [16]-[21].
The design of resilient control systems pivots on the fundamental
system tradeoffs between robustness, resilience,
and security. Perfect security could be achieved by making
the system unusable, and likewise perfect robustness could
be attained by making the control performance completely
inadequate. The need for resilience is due to the fact that no
desirable control systems exhibit perfect robustness or
security. Hence, it is imperative in the control design to
know what type of uncertainties or malicious events need
to be considered for enhancing robustness and security
and what uncertainties or malicious events need to
FEBRUARY 2015 « IEEE CONTROL SYSTEMS MAGAZINE 47
be considered for post-event resilience. Studying these
tradeoffs requires extending the control system design
problem to include the cyberlayers of the system and
understand the cross-layer issues in cyberphysical systems.
Resilient control, however, poses new challenges, different
from the ones encountered in robust control and security
games. Resiliency should be considered together with
robustness and security since the post-event resiliency
relies on the pre-event designs. Resilience builds upon
robustness and security frameworks and takes a crosslayer
approach by considering post-event system features.
Since game theory has been successfully applied to study
robustness and security, it is natural to adopt it as the main
tool to build an extended and integrated framework.
The goal of this article is to introduce game-theoretic
methods for resilient control design and develop a framework
that studies the tradeoff between robustness, security,
and resilience. A hybrid dynamic game-theoretic
approach is introduced that integrates the discrete-time
Markov model for modeling the evolution of cyberstates
with continuous-time dynamics for describing the underlying
controlled physical process. The hybrid dynamic
game model provides a holistic and cross-layer viewpoint
in the decision-making and design for cyberphysical systems.
The continuous-time dynamics model the physical
layer, that is, the plant, subject to disturbances and control
efforts. The discrete-time dynamics model the cyberlayer
of the system, which involves system configurations and
dynamic human-machine interactions (HMIs). A zerosum
differential game is used for robust control design at
Game Theory in a Nutshell
G tiple decision makes, called players. Each player's preferame
theory deals with strategic interactions among mulence
ordering among multiple alternatives is captured in an objective
function for that player. Players try to maximize (for utility
or benefit functions) or minimize (for cost or loss functions) their
respective objective functions. For a nontrivial game, the objective
function of a player depends on the choices (actions, or
equivalently decision variables) of at least one other player, and
generally of all the players, and hence players cannot simply
optimize their own objective function independent of the choices
of the other players. This introduces a coupling between the
actions of the players and binds them together in decision making
even in a noncooperative environment.
A noncooperative game is nonzero sum if the sum of the players'
objective functions cannot be made zero even after appropriate
positive scaling and/or translation that do not depend on the
players' decision variables. A two-player game is zero sum if the
sum of the objective functions of the two players is zero or can be
made zero by appropriate positive scaling and translation that do
not depend on the decision variables of the players. A game is
a finite game if each player has only a finite number of alterna48
IEEE CONTROL SYSTEMS MAGAZINE » FEBRUARY 2015
the physical layer, while a stochastic zero-sum game
between an administrator and an attacker is used for the
design of defense mechanisms. The controlled transition
between pre-event states to post-event states in the hybrid
system framework leads to the design of the resilient hybrid
dynamical system. The controller design at the physical
layer and the security policy design at the cyberlayer of the
system are intertwined. A policy made at the cyberlayer
can influence the optimal control design for the physical
system, and the optimal control design at the lower level
needs to be taken into account when security policies are
determined. For a class of system models, the overall optimal
design of the cyberphysical system can be characterized
by a Hamilton-Jacobi-Isaacs (HJI) equation together
with a Shapley optimality criterion. The notations used in
the article are summarized in Table 1 for the reader's convenience.
For a brief introduction to game theory, see “Game
Theory in a Nutshell”.
HIERARCHICAL SYSTEMS
A cross-layer approach is pivotal for designing resilient
control systems. Integrating physical control systems with
cyberinfrastructure to allow for new levels of HMI has
been a growing trend in the past few decades. To manage
the increasing complexity of cyberphysical systems, it is
essential that control designs exploit the hierarchical nature
of such systems [22], [23]. Depicted in Figure 1, a cyberphysical
control system can be conceptually divided into six
layers: physical, control, communication, network, supervisory,
and management.
tives, that is, the players pick their actions out of finite sets (action
sets); otherwise the game is an infinite game; finite games are also
known as matrix games. An infinite game is said to be a continuous-kernel
game if the actions sets of the players are subsets of
finite-dimensional vector spaces, and the players' objective functions
are continuous with respect to action variables of all players.
A game is said to be deterministic if the players' actions uniquely
determine the outcome, as captured in the objective functions,
whereas if the objective function of at least one player depends
on an additional variable (state of nature) with a known probability
distribution, then the game is a stochastic game. A game is a
complete information game if the description of the game [that is,
the players, the objective functions, and the underlying probability
distributions (if stochastic)] is common information to all players;
otherwise it is an incomplete information game. Finally, a game is
static if each player acts only once, and none of the players has
access to information on the actions of any of the other players;
otherwise it is a dynamic game. A dynamic game is said to be
a differential game if the evolution of the decision process (controlled
by the players over time) takes place in continuous time,
and generally involves a differential equation.
Management Layer
Supervisory Layer
Network Layer
Communication Layer
Control Layer
Physical Layer
Human Layer
Cyber Layer
Physical Layer
f iGure 1 The hierarchical structure of cyberphysical control systems
composed of six layers. The physical layer deals with the
physical devices or chemical processes, such as electric machines
and transmission lines of power system infrastructure, and electric
vehicles in transportation networks. The control layer monitors
and controls the physical layer system for achieving desired
system performance. The communication layer provides wired or
wireless data communications that enable advanced monitoring
and intelligent control. The networking layer allocates network
resources for routing and provides interconnections between
system nodes. The supervisory layer is the executive brain of the
entire system, provides human-machine interactions, and coordinates
and manages lower layers through a centralized command
and control. The management layer resides at the highest echelon.
It deals with social and economic issues, such as market
regulation, pricing, and incentives.
The physical layer comprises the physical plant to be controlled.
The control layer consists of multiple control components,
including observers/sensors, intrusion detection
systems (IDSs), actuators, and other intelligent control components.
The physical layer together with the control layer can be
viewed as the physical world of the system. On top of these
two layers are the communication layer, which establishes
physical layer wired or wireless communications, and the network
layer that allocates resources and manages routing. The
communication and network layers constitute the cyberworld
of the system. Note that these two layers generally represent
all the layers of open system interconnection (OSI) model [24],
[25], which can be incorporated into the cyberlayers of the
system. The supervisory layer serves as the brain of the
system, coordinating all lower layers by designing and sending
appropriate commands. The management layer is a higher
level decision-making engine, where the decision makers take
an economic perspective towards the resource allocation
problems in control systems. The supervisory and management
layers are often interfaced with humans, and hence they
contain human factor issues and HMIs.
Cybersystem
Physical Plant
Cyber
Attack
a
i
Cyberdefense
l
x
Control
u
Disturbances
w
f iGure 2 The interactions between the cyber and physical systems
are captured by their dynamics. The physical system state
x(t) is controlled by u with the presence of disturbances and noises.
The cyberstate i(t) is controlled by the defense mechanism l
used by the network administrator as well as the attacker's action
a. A cyberattack can compromise the controller and the plant
through their coupling with the cybersystem.
The layered architecture can facilitate the understanding
of the cross-layer interactions between the physical layers
and the cyberlayers. In Figure 2, x (t) and i (t) denote the
continuous physical state and the discrete cyberstate of the
system, which are governed by the laws f and K, respectively.
The physical state x (t) is subject to disturbances w
and can be controlled by u. The cyberstate i (t) is controlled
by the defense mechanism l used by the network administrator
as well as the attacker's action a. The hybrid nature of
the cross-layer interaction leads to the adoption of a class of
hybrid system models, as will be seen later.
PHYSICAL LAYER CONTROL SYSTEM PROb LEM
Resilient control requires a cross-layer control design. The
control problem at the physical layer of the system is
described below. Consider a general class of systems subject
to two types of uncertainty: 1) a continuous deterministic
uncertainty that models the known parametric
uncertainties and disturbances and 2) a discrete stochastic
uncertainty that models the unknown and unanticipated
events that lead to a change in the system operation state at
random times. Let the system state evolve according to the
piecewise deterministic dynamics
xo (t) = f (t, x, u, w; i (t, a, l)),
x (t0) = x0,
(1)
where x (t) ! Rn, x0 is a fixed (known) initial state of the
physical plant at starting time t0, u (t) ! Rr is the control
input, w (t) ! Rp is the disturbance, and all these quantities
lie at the physical and control layers of the entire system.
The state of the cybersystem is described by i. The evolution
of i depends on the cyberdefense action l and the
attacker's action a, which are also functions of time. i (t) is a
shorthand notation in place of i (t, a, l) if the pair of actions
(a, l) is fixed. For a given pair (a, l), i (t), t ! [0, t f], is a Markov
jump process with right-continuous sample paths, with
FEBRUARY 2015 « IEEE CONTROL SYSTEMS MAGAZINE 49
initial distribution r0, and with rate matrix m = {mij} i,j ! S,
where S: = {1, 2, f, s} is the state space; mij ! R+ are the transition 
rates such that for i ! j, mij $ 0, and mii = 1 - / j ! i mij
for i ! S.
Transitions between the structural states are controlled
by the attacker and the system administrator. An attacker
can exploit the vulnerabilities in the control system software
and launch an attack to bring down the operation. An
example is Stuxnet, a Windows-based worm that was
recently discovered to target industrial software and equipment
[3]. An administrator can enforce security by dynamically
updating the security policy of the control systems
[26], [27]. Once an attack occurs, the administrator can
restore the system back to normal operation. Different from
conventional computer networks, control systems are
reported to experience lower rates of attacks [28], and the
software updates are less frequent than the ones in computer
networks. Hence, the transition between structural
states are at a different time scale from the evolution of
physical states. The systems are assumed to have reached
their physical steady states when the structural transition
happens. This assumption is validated from the fact that the
attack rate on control systems is often lower than the one on
information systems [29], [30] and the fact that the time scale
of the failure rate of devices and components in control systems
is higher than the one of the system dynamics and
operations [31].
Cyberstrategy
Let kr = t/f, f > 0, be the time scale on which cyberevents
happen, which is often on the order of days, in contrast to
the one of the physical systems which evolve on the time
scale of seconds. Denote by a ! A a cyberattack chosen by
the attacker from his attack space A := {a1, a2, f, aM} composed
of all M possible actions. l ! L is the cyberdefense
mechanism that can be employed by the network administrator,
where L := {l1, l2, f, lN} is the set of all the possible
defense actions. Without loss of generality, A and L do
not change with time even though, in practice, they can
change due to technological updates and advances. The
mixed strategies f (k) = [ fi (k)] iN=1 ! Fk, g (k) = [gj (k)] Mj=1 ! Gk
of the defender and the attacker, respectively, are considered
here, where fi (k) and gj (k) are the probabilities of
choosing li ! L and a j ! A, respectively, where Fk and Gk
are sets of admissible strategies, defined by
N
Fk := )f (k) ! [0, 1] N: / fi (k) = 13,
i =1
M
Gk := )g (k) ! [0, 1] M: / g j (k) = 13.
j =1
The transition law of the cybersystem state i (k) at time k
depends on the actions of the attacker as well as the defense
mechanism employed by the administrator. More precisely,
the rate matrix has
50 IEEE CONTROL SYSTEMS MAGAZINE » FEBRUARY 2015
(4)
(5)
mij (f (k), g (k)), j ! i,
Prob {i (k + D) = j|i (k) = i} = )mii (f (k), g (k)), j = i,
where D > 0, which is on the same time scale as k (for
example, days), and mij (f (k), g (k)) are the average transition
rates in terms of the transition rates muij (a (k), l (k)), i, j ! S,
defined by
N M
mij (f (k), g (k)) = / / fi (k) g j (k) muij (ai (k), l j (k)) .
i =1 j =1
Equations (1) and (4) describe hybrid systems [32]-[34]
with both continuous and discrete states. Let Ft be the
sigma-field generated by i[t0,t] := {i (s), s # t}. The admissible
control and disturbance processes, u ($) and w ($), are taken
to be Ft measurable and piecewise continuous, with the
corresponding spaces denoted by U and W, respectively.
f is taken to be piecewise continuous in t and Lipschitz
continuous in (x, u, w), for each fixed sample path of i, with
probability one. The process i models the unanticipated or
rare uncertainties that arise from cyberattacks or component
failure. These events result in random structural
changes in the dynamics of the system. For each
u ! U, w ! W, the state process x ($) is continuous with
probability one, and if (u, w) is chosen to be memoryless,
then the pair (x, i) is a Markov process.
Closed-Loop, Perfect-State Feedback Control
A closed-loop, perfect-state information structure is considered
for control design. The controller has access to x[t0,t]
at time t, which can be written as
u (t) = n (t, x[t0,t]; i[t0,t]),
t ! [t0, t f],
(6)
where n is an admissible closed-loop control strategy,
piecewise continuous in its first argument, and Lipschitz
continuous in its second argument. The class of all such
control strategies is denoted by MCL 3 U. Analogously, let
NCL 3 W denote the class of all closed-loop disturbance
strategies
w (t) = o (t, x[t0,t]; i[t0,t]),
t ! [t0, t f] .
(7)
The performance index for the hybrid control system is
given by the expected cost over the statistics of i
J (u, w) := Ei {L (x, u, w; i)},
(8)
(2)
(3)
with the cost function L given as
L (x, u, w; i) = q f (x (t f); i (t f))
+ # t f c (t, x (t), u (t), w (t); i (t)) dt + c0 (x0; i (t0)),
t0 (9)
where q f is continuous in x, and g is jointly continuous in
(t, x, u, w) . In the infinite-horizon case, q f is dropped out,
and t f " 3. For each nCL ! MCL and oCL ! NCL, the stochastic
differential equation will admit a well-defined solution
(as a piecewise deterministic process), which will induce
corresponding unique elements in U and W, which is the
“open-loop representations” of n and o, respectively.
The H3-optimal control problem in the time domain is
in fact a minimax optimization problem, and hence a zerosum
game, where the controller can be viewed as the minimizing
player and the disturbance as the maximizing
player [13], [35]. Here, the objective is to find a minimax
closed-loop controller n*CL ! MCL that infimizes the supremum
of J over all closed-loop disturbance policies
sup J (n*CL, o) = inf sup J (n, o) .
o ! NCL n ! MCL o ! NCL
(10)
-Vit (t, x) = ui!nRfrwsu!Rpp'Vix (t, x) f (t, x, u, w, i)
Vi (t f, x) = q f (x (t f); i),
+ c (t, x, u, w, i) + / mij Vj (t, x)1,
j ! S
i ! S,
(14)
(15)
where the simpler notation Vi (t, x) is used in place of
V (t, x; i (t) = i) . Denoting any such control by nF ! MCL,
(14) and (15) can be rewritten as
-Vit (t, x) = sup 'Vix (t, x) f (t, x, nF (t, x, i), w, i)
w ! Rp
+ c^t, x, nF ^t, x, ih, w, ih + / mij Vj ^t, xh1.
j ! S
A cost structure of interest is the separable one
c (t, x, u, w; i) = c0 (t, x, u; i) - c2 r (w; i) .
The solution of (10) parameterized in c is denoted by n*c,
and cCL denotes the smallest value of c > 0 such that for
c > cCL the right-hand side of (10) is bounded. Then n*c for
c > cCL is an H3 controller for the hybrid system, with
respect to the performance index
sup *
w ! W
Ei {q f (x f; i (t f)) + # t f
t0
Ei { w 2 + q0 (x0; i (t0))}
c0 (t, x (t), u (t); i (t)) dt}
4,
(12)
where $ denotes the L2-norm of w for each sample path
of i. The minimum value of (12) is c2CL . It defines a measure
of disturbance attenuation in the nonlinear hybrid system.
Note that in (10), x0 is considered as part of the disturbance.
What has been formulated above, as described by (10), is
a differential game. Let V ($) : R # Rn # S denote the cost-togo
function associated with this differential game, that is,
V (t, x, i) is the upper value of a similar game defined on the
shorter interval [t, t f], with initial state x, and initial structure
i (t) = i. The following assumptions are quite standard.
A1): The differential game defined by (10) has an upper
value V for every initial time t, state x (t), and
structure i (t), which is jointly continuously differentiable
in (t, x) .
Under A1), the infinitesimal generator of the uppervalue
function is
LV (t, x; i)|i =i := lhi"m0 1h E {V (t + h, x (t + h); i (t + h))
- V (t, x (t), i (t))|x (t) = x, i (t) = i}
s
= Vt (t, x; i) + Vx (t, x; i) f (t, x, u, w; i) + / mij Vt,x;j,
j =1
(13)
with u ! U and w ! W chosen to be memoryless, which
in fact is not a restriction as further elaborated below. From
(13), the associated HJI equation is
Furthermore, if the Isaacs condition [on interchangeability
of infimum and supremum in (14)] holds and if there exists
a disturbance policy, oF ! NCL, that achieves the maximum
(11) in (14), then oF is also a Markov policy, and (nF, oF) are in
saddle-point equilibrium. In this case, the upper value is
also the value function, satisfying the partial differential
equation (PDE)
-Vit (t, x) = Vix (t, x) f (t, x, nF (t, x, i), oF (t, x, i), i)
+ c (t, x, nF (t, x, i), oF (t, x, i), i) + / mij Vj (t, x). (16)
j ! S
For details on the equilibrium concepts of games, see “General
Game Model and Equilibrium Concept.” The preceding
discussion and the ensuing result are now summarized
in the theorem below.
Theorem 1
Let the cyberstrategy pair (f (k), g (k)) be fixed, A1) hold, and
nF ! MCL be defined as above. Then, nF is a closed-loop
minimax controller. If, furthermore, the Isaacs condition
holds and oF ! NCL is defined above, the pair of Markov
policies (nF, oF) provides a saddle-point solution on the
product space MCL # NCL . The corresponding saddle-point
value function solves (16) subject to (15). 4
The optimal cost Vi (t0, x0) yields the physical layer control
performance under the minimax controller. Note that
this cost depends on the cyberstrategy pair (f, g) since the
transition rate mij is a function of mixed strategies. The
cyberstrategies are determined by analyzing a security
game at the cyberlayer.
CYb ERLAYER DEf ENSE SYSTEM
At the cyberlayer, a zero-sum game framework can be used
to capture the strategic interactions between an attacker
and a defender. The game takes different forms depending
on the information available to the defender, the targets of
the attacker, and the security mechanism. For example, a
zero-sum stochastic game has been used for dynamic configurations
of a network of IDSs [36], [37], in which the state
FEBRUARY 2015 « IEEE CONTROL SYSTEMS MAGAZINE 51
General Game Model and Equilibrium Concept
Cthe players set. The decision or action variable of Player = L(x)1,x)2) =:L), (S2)
onsider an N-player game, with N := {1,f,N} denoting xm1!inX1 mx2!aXx2 L(x1,x2) = mx2!aXx2 xm1!inX1 L(x1,x2), (S1)
i is denoted by xi ! Xi, where Xi is the action set of Player i.
Let x denote the N-tuple of actions variables of all players,
x := (x1,f,xN). Allowing for possibly coupled constraints, where the first expression in (S1) is known as the upper value
let X 1 X be the constraint set for the game, where X is the of the game, the second expression in (S1) is the lower valN
-product of X1,f,XN; hence for an N-tuple of action variables ue of the game, and L) is known as the value of the game.
to be feasible, x ! X. The players are minimizers, with the ob- Upper and lower values are, in fact, defined in more general
jective function (loss function or cost function) of Player i de- terms using infimum (inf) and supremum (sup) replacing mininoted
by Li (xi,x-i), where x-i stands for the action variables of mum and maximum, respectively, to account for the facts that
all players except the ith one. minima and maxima may not exist. When the action sets are
Now, an N-tuple of action variables x* ! X is a Nash equi- finite, however, the latter always exists. Note that the value of a
librium (or noncooperative equilibrium) if, for all i ! N, xi ! Xi, game, whenever it exists (which certainly does if there exists a
saddle point), is unique. Hence, if there exists another saddleLi
(xi*,x-*i) # Li (xi,x-*i), such that (xi,x*-i) ! X. point solution, say (tx1,tx2), then L(tx1,tx2) = L). Moreover, these
If N = 2 and L1 / -L2 =:L, then the game is a two-player zero- multiple saddle points are orderly interchangeable, that is the
sum game, with Player 1 minimizing L and Player 2 maximizing pairs (x)1,tx2) and (tx1,x)2) are also in saddle-point equilibrium.
the same quantity. In this case, the Nash equilibrium becomes This property of saddle-point equilibria does not extend to multhe
saddle-point equilibrium, which is formally defined as fol- tiple Nash equilibria (for nonzero-sum games). Multiple Nash
lows, where the coupling constraint X is left out (or simply as- equilibria are generally not interchangeable, and further they do
sumed to be equal to the product set X := X1 # X2 ): A pair of not lead to the same values for the players' cost functions, the
actions (x*1,x*2) ! X is in saddle-point equilibrium for a game implication being that when players switch from one equilibrium
with cost function L, if for all (x1,x2) ! X, to another, some players may benefit from that (in terms of reduction
in cost) while others may see an increase in their costs.
L(x*1,x2) # L(x*1,x*2) # L(x1,x*2).
Further, if the players pick randomly (for their actions) from the
This also implies that the order in which minimization and maxi- multiple Nash equilibria of the game, then the resulting N-tuple
mization are carried out is inconsequential, that is, of actions may not be in Nash equilibrium.
of the system evolves according to transition rules determined
by the actions taken by the players, and dynamic
system configuration policy has been developed for IDSs to
optimally defend against intrusions. In [38] and [39], a multistage
Stackelberg game has been studied for developing
deceptive routing strategies for nodes in a multihop wireless
communication network. The framework is convenient
to model the scenario where the defender first deploys a
proactive defense, and the attacker follows the protocol. A
stochastic repeated game and an iterative learning mechanism
have been adopted for moving target defense [40],
[41]. Due to the lack of complete information of the attacker
and the system itself, the players update their strategies in
a feedback manner driven by the data they have observed
from the system.
In this article, a general stochastic game formulation is
introduced in which the state space coincides with S. This
class of models captures the uncertainties in cybersystem
dynamics and the time evolution of system states and
player strategies. Moreover, in the absence of decision
making of the players (that is, the costs and the transitions
are independent of player strategies), the framework would
be reduced to a Markov-chain model which has been used
for reliability analysis [42].
52 IEEE CONTROL SYSTEMS MAGAZINE » FEBRUARY 2015
At time k ! R+, the action pair (a, l) is chosen by the
attacker and the defender according to a mixed strategy
pair (f (k), g (k)) as introduced in (2) and (3). The joint actions
affect the transition rates mij in (4) and also incur a cost
ci (a, l; nCL, oCL), where ci is a bounded cost function that
incorporates the physical layer control system performance
under the closed-loop strategies nCL, oCL . The cost ci has
two components: the cost inflicted on the cyberlayer and
the resulting impact-aware, physical-layer performance
index from the action pair (a, l) .
The defense against attacks involves HMIs, which occur
at the human and cyberlayers of the system. Hence, defense
often evolves on a longer time-scale than the physical layer
processes. Using time-scale separation, the optimal defense
mechanism can be designed by viewing the physical control
system at its steady state at each cyberstate i at a given
time k. The interaction between an attacker and a defending
administrator can be captured by a zero-sum stochastic
game with the defender aiming to maximize the long-term
system performance or payoff function whereas the
attacker aiming to minimize it [43]. A discounted payoff
criterion vb (i, f, g) is used and it is defined as
vb (i, f, g) := #0 3 e-bk Eif(k),g(k) ci (a, l; nCL, oCL) dk,
where b is the discount factor. The operator Eif,g is the
expectation operator. Here a class of mixed stationary strategies
fi ! Fi and gi ! Gi, i ! S, is considered that are only
dependent on the current cyberstate i. Let F = {fi} i ! S ! FS
and G = {gi} i ! S ! GS, where FS := Pi ! S F i and GS :=
Pi ! S Gi. The following theorem characterizes the stationary
saddle-point equilibrium of the stochastic zero-sum
game in a similar fashion as in [43]-[46] .
Theorem 2 [18]
Let the strategy pair (nCL, oCL) be fixed. Assume that mij (k)
are continuous in fi, and gi and the cost functions ci are
bounded. Then, there exists a pair of stationary strategies
(F*, G*) ! FS # GS such that, for all i ! S, the following
fixed point equation is satisfied
bv*b (i) = uci (F*, G*) + / mij (F*, G*) v*b (j)
j ! S
= sup uci (F, G*) + / mij (F, G*) v*b (j)1
F ! FS' j ! S
= Gi!nGf S'uci (F*, G) + j /!S mij (F*, G) v*b (j)1
= sup inf uci (F, G) + / mij (F, G) v*b (j)1
F ! FS G ! GS' j ! S
=: Lb (i)
= inf sup uci (F, G) + / mij (F, G) v*b (j)1
G ! GS F ! FS' j ! S
=: Ub (i),
(17)
(18)
Note that the equilibrium solution {F*, G*} depends on
the physical layer minimax control (n*CL, o*CL), while finding
the control policy (n*CL, o*CL) using (14) and (15) relies on the
security policy {F*, G*} taken at the cyberlayer. The optimality
criterion (17) in Theorem 2 together with the HJI equation
in (14) defines a set of coupled optimality conditions that are
used to solve for obtaining the cyberpolicy F) and the robust
controller n*CL and its associated performance index c).
The coupling between the cybersystem game (CSG) and
the physical system game (PSG) captures the essential tradeoffs
between robustness, resilience, and security. To ensure
that the system operates in a normal condition, either a perfect
secure system is designed so that no attack can succeed
or the system is capable of recovering back to its normal condition
quickly once it fails. However, given limited resources,
perfect security is not possible, and the solution to the cybergame
(for good states) provides a fundamental limit for the
best-effort security strategies. Hence, it is essential to allocate
resources to the cybersystem to recover from the failure
states. This security and resilience tradeoff is captured by the
stochastic CSG introduced in this section, which yields strategies
balancing the level of security that prevents the cybersystem
from failure, and the level of resilience that brings the
system quickly back to its normal state of operation.
On the other hand, to achieve a higher level of robustness,
the control effort has to be distributed across different
cyberstates. Robustness of the control system is high if the
system is perfectly secure, that is, the system does not fail
and does not move to a compromised state, because control
effort only needs to be expended for the good states. However,
perfect security does not exist, and the control effort
has to be expended on the bad states as well in case the
system fails to ensure robustness at the failure states.
Hence, there is a tradeoff between security and robustness.
The formulation of the PSG captures this tradeoff.
In addition, the coupling between the CSG and PSG yields a
design relationship between the level of robustness against w
in the physical system and the cost for security defense against
G in the cybersystem. A higher demand of robustness at the
physical level will lead to a higher control cost and a higher
impact cost for the cybersystem once the system is compromised,
which in turn requires a stronger level of security and
resilience to prevent or recover from the failure. Given limited
resources for defense, physical-level robustness will dictate the
tradeoff relationship between security and resilience. Hence, as
a result of this framework, a balance of security, resilience, and
robustness is achieved for the cyberphysical control system.
LINEAR-QuADRATIC PROb LEM w ITH
CASCADING AfIL u RES
Linear Quadratic Problem
The set of optimality equations can be simplified by considering
the special case of the linear quadratic problem
defined as
FEBRUARY 2015 « IEEE CONTROL SYSTEMS MAGAZINE 53
where uci (F, G) is a shorthand notation for EF,G ci (a, l; nCL, oCL),
and Lb (i), Ub (i) are defined to be respectively the lower
value and the upper value of the game. In addition, (F*, G*)
from (17) is a pair of saddle-point equilibrium strategies
and the value of game v*b (i) is unique and has the property
that v*b (i) = Lb (i) = Ub (i) . 4
The above result is also known as the Shapley optimality
criterion for stochastic games. For more details on the
properties of saddle points of zero-sum games, see “Minimax
Theorem.” The saddle-point equilibrium strategies
can be computed using a value iteration scheme [44], [45].
Let {vnb (i)} n3=1 be a sequence of values of the game which
obeys the following update law
vnb+1 (i) = uci (Fn*, Gn*) + / mij (Fn*, Gn*) vnb ( j)
j ! S
= sup uci (Fn, Gn*) + / mij (Fn, Gn*) vnb ( j)1
F ! FS' j ! S
= Gi!nGf S'uci (Fn*, Gn) + j /!S mij (Fn*, Gn) vnb ( j)1.
The following theorem provides a convergence result on
the iterative algorithm in (18).
Theorem 3
Let {Fn*, Gn*} be the sequence of strategies in FS # GS produced
by the value iteration scheme described in (18). Then,
any limit point (Fn, Gn) of the sequence is a pair of saddlepoint
equilibrium strategies. Moreover, the limit point
yields the unique game value v*b (i), i ! S. 4
Minimax Theorem
Cmatrix games, where Player 1 is the minimizer and Player 2
onsider two-person, zero-sum finite games, or equivalently
the maximizer. Let X1 and X2 be Player 1's and Player 2's action
sets, respectively. Let card (X1) = m and card (X2) = n be
the cardinality of action sets, that is the minimizer has m choices
and the maximizer has n choices. The objective function
L(x1,x2) is defined on X1 # X2. Equivalently, an m # n matrix A
can be associated with this game, whose entries are the values
of L(x1,x2), following the same ordering as that of the elements
of the action sets, that is ijth entry of A is the value of L(x1,x2)
when x1 is the ith element of X1 and x2 is the jth element of
X2. Player 1's choices are then the rows of the matrix A and
Player 2's are its columns.
In general, a saddle point may not exist in pure strategies
for all zero-sum games. One example is the game known as
Matching Pennies. Each player has a penny and can choose
heads or tails. The players then reveal their choices simultaneously.
If the two choices are identical (that is, if they match),
then Player 1 wins and is given the other player's penny. If the
choices do not match, then Player 2 wins and is given the other
player's penny. This is an example of a zero-sum game, where
one player's gain is exactly equal to the other player's loss. The
game matrix associated with the game is
-1 1
A = c 1 -1m.
The entries of this matrix are losses to Player 1 (and thus gain
to Player 2). The first row corresponds to the choice of heads for
Player 1, and the second row corresponds to the choice of tails
for him. Symmetrically, the first column corresponds to heads
for Player 1, and the second column is tails for him. Here there is
no row-column combination at which the players would not have
an incentive to unilaterally deviate and improve their returns.
This opens the door for looking for a mixed-strategy equilibrium.
A mixed strategy for Player i is a probability distribution
over his action set Xi, which is denoted by pi for Player i. If Xi
is finite, which is the case here, then pi will be a probability
f (t, x, u, w; i) = Ai x + Bi u + Di w,
q f (t f; i) = |x (t f)|Q2itf,
q0 (x0, i) = |x0|2Qi0,
c0 (t, x, u, i) = |x|2Qitf +|u|2Ri,
r (w; i) = |w|2,
(19)
(20)
(21)
(22)
(23)
where i ! S, | $| denotes the Euclidean norm with appropriate
weighting, and Ai, Bi, Di, Qi, Ri are matrices of appropriate
dimensions, whose entries are continuous functions
of time t. Further, Qi ($) $ 0, Ri ($) > 0, and Qi0 > 0 and Qif $ 0.
Consider the infinite horizon case with the cost function
defined by
54 IEEE CONTROL SYSTEMS MAGAZINE » FEBRUARY 2015
vector, taking values in the probability simplex determined by
Xi, which is denoted by Pi . A pair (p)1,p)2) constitutes a saddle
point in mixed strategies (or a mixed-strategy saddle-point
equilibrium), if for all (p1,p2) ! P,
J(p)1,p2) # J(p)1,p)2) # J(p1,p)2),
where J(p1,p2) = Ep1,p2 6L(x1,x2)@, and P := P1 # P2. Here J) =
J(p)1,p)2) is the value of the zero-sum game in mixed strategies.
In terms of the matrix A, and the probability vectors p1 and
p2 (both column vectors), which were introduced earlier (note
that in this case p1 is of dimension m and p2 is of dimension
n, and components of each are nonnegative and add up to
one), the expected cost function can be rewritten as
J(p1,p2) = pl1Ap2.
By the minimax theorem [52], J admits a saddle point, which
means that the matrix game A has a saddle point in mixed
strategies, that is there exists a pair (p)1,p)2) such that for all
other probability vectors p1 and p2, of dimensions m and n,
respectively, the following pair of saddle-point inequalities hold
p)1lAp2 # p1)lAp)2 # pl1Ap)2.
The quantity p)1lAp)2 is the value of the game in mixed strategies.
This result is now captured in the following theorem.
THEOREM S1 (MINIMAx THEOREM)
Every finite two-person, zero-sum game has a saddle point in
mixed strategies.
The extension of this result to N-player finite games was
first obtained in [49], as captured in the following theorem.
THEOREM S2
Every finite N-player nonzero-sum game has a Nash equilibrium
in mixed strategies.
A standard proof for this result uses Brouwer's fixed point
theorem; see [35].
L (x, u, w; i) = E # 3 (|x (t)|2Qi +|u (t)|2Ri - c2|w (t)|2) dt.
t0
(24)
Before stating Theorem 4, the following assumptions
are made
A2): The Markov chain i is irreducible for any admissible
strategies [47, p. 78].
A3): The pair (Ai, Bi) is stochastically stabilizable [48, see
its definition on p. 59].
A4): The pair (Ai, Qi) is observable for each i ! S.
Theorem 4 [33]
Consider the soft-constrained, zero-sum differential game
with perfect measurements in the infinite-horizon case
p1 = m12
pN - 1 = mN - 1, N
1
2
N - 1
N
f iGure 3 A system progresses from a normal operating state
i = 1 to the failure state N. The intermediate states are the ones
in which part of the system is exploited and attacked due to the
launch of a multistage attack. The transition between the cyberstates
follows a Markov process with rate mi,i+1 = pi,1 # i # N -1,
and mii = 1 -pi,1 # i # N -1,mNN = pN.
defined by (10), (19)-(23), (24), (6), and (7), with mijs fixed. Let
assumptions A2)-A4) hold. Then, c*CL,3 < + 3, and for any
cCL > c*CL,3, there exists a set of minimal positive definite
solutions Zi, i ! S, to generalized algebraic Riccati equations
(GAREs),
Ai< Zi + Zi Ai - Zi cBi (Ri) -1 Bi < - 12 Di Di <mZi
c
s
+ Qi + / mij (F, G) Zj = 0; i ! S,
j =1
which further satisfy the condition
c2CL Qi0 - Zi $ 0, i ! S,
(25)
and a strategy n*c3 for P1 that guarantees the zero upper
value is
u*c3 (t) = n*c3 (t, x (t), i (t)) =-(Ri) -1 Bi< Zi x (t) .
(26)
For almost all c > c*3, the jump linear system driven by
both the optimal control and the optimal disturbance,
xo (t) = c Ai - (Bi (Ri) -1 Bi < - 12 Di Di <) Zimx (t),
c
(27)
is also mean-square stable, that is, limt " 3 E {|x (t)|2} = 0.
For c < c*CL,3, on the other hand, either condition (25) is
not satisfied or the set of GAREs does not admit nonnegative
definite solutions, and in both cases, the upper value of
the game is +3.
On a longer time scale, the continuous-time, zero-sum
game between the attacker and the administrator has the
stationary saddle-point equilibrium characterized by Theorem
2. Let ugi = Vi be the cost function which describes the
physical layer system performance. Then, the fixed-point
equation (17) can be written as
bv*b (i) = xl0 Zi (F*, G*) x0 + / mij (F*, G*) v*b ( j) .
j ! S
The optimal control u* and the optimal defense strategy F*
need to be found by solving the coupled equations (28) and
GAREs in Theorem 4.
Cascading Failures
Cascading failure is kind of failure in a system comprised
of interconnected parts in which the failure of a part can
trigger the failure of successive parts. Such a failure is
common in computer networks and power systems. In the
case of cascading failures, state i = 1 is the normal operating
state and state i = N is the terminal failure state. The
states i, 2 # i # N - 1, are intermediate compromised states
in which one system component failure leads to another.
The failure and compromised states are taken to be irreversible,
that is, the system cannot be fixed or brought
back to its normal state immediately after faults occur. This
is usually due to the fact that the time scale for critical cascading
failures is much shorter than the time scale for
system maintenance. In our modeling framework, the transition
between the failure states follows a Markov jump
process with rate matrix m = {mij} i,j ! S such that for
i ! j, mij $ 0, mii = 1 -/ j ! i mij, and i > j and j > i + 1, mij = 0.
For simplicity, the notation mi,i+1 = pi, 1 # i # N - 1, denotes
the transition rates between adjacent states, and hence
mii = 1 - pi, 1 # i # N - 1, pN = mNN . Here, pi, i = 1, g, N - 1,
are dependent on the cyberstrategy pair (F, G), which has
been introduced earlier. An effective cyberdefense action
will lead to lower transition rates, and a power cyberattack
will increase them. The structure of state transition of cascading
failures is depicted in Figure 3.
Following (28), the optimality criteria for the cybersystem
under cascading cyberstates can be further simplified to
bv*b (N) = VN,
bv*b (i) = val {ci + pi v*b (i + 1) - pi v*b (i)},
(fi, gi) ! arg val {ci + pi v*b (i + 1) - pi v*b (i)},
i = 1, g, N - 1,
ci = x0< Zi x0 .
Here, pi = mi,i+1, 1 # i # N - 1, and Vi is dependent on pi
through Zi in Theorem 4. Note that (30) and (31) find the
game value vib and stationary saddle-point equilibrium
strategies (F, G), respectively. Since both players have a
finite number of choices for each k, the existence of a saddle-point
solution is guaranteed for the zero-sum stochastic
game [35], [49].
In addition, the optimality criteria for the H3 optimal
control in the linear quadratic case can be reduced to
AN < ZN +ZN AN -ZN cBN (RN) -1 BN <- 12 DN DN <mZN +QN =0,
c
(29)
(30)
(31)
(32)
(28)
Ai < Zi +Zi Ai -Zi cBi (Ri) -1 Bi < - 12 Di Di <mZi +Qi +pi Zi+1 =0,
c
i = 1, f, N - 1.
(33)
Here, c is a chosen level of attenuation. Under the regularity
conditions in [13], there exists a finite scalar c3 > 0 such
FEBRUARY 2015 « IEEE CONTROL SYSTEMS MAGAZINE 55
Cybersystem Game
vb, F, G
Physical System Game
Vi, nCL, vCL
f iGure 4 A games-in-games structure for cross-layer resilient
control design. At the physical layer control system, a zero-sum
differential game between the robust controller and the disturbance
is used to design an H3 controller for achieving robust performance
for uncertain parameters or disturbances. At the
cyberlayer defense system, a zero-sum stochastic game between
a defender and an attacker is used to design an optimal cyberpolicy
for ensuring system security. The cross-layer solution
(nCL,oCL,F,G) has to satisfy a Hamilton-Jacobi-Isaacs equation
and a Shapley optimality criterion. Vi is the value function for the
physical system at cybermode i, and vb(i) is the value function for
the cybersystem. The solution process is composed of a zoomingin
process and a zooming-out process. The zooming-in operation
goes from the cyberlayer decision process to the physical layer
one, while the zooming-out operation refers to the reverse.
that for all c > c3, (32) and (33) admit unique minimal nonnegative
definite solutions.
In (30), pis are dependent on F and G. At the same time,
as a result of solving (33), the value Vi is dependent on pis
and Bis, which are in turn functions of F and G. The above
set of coupled equations can be solved by starting with (32)
for obtaining the value of the terminal state VN. From (29),
the value v*N is calculated and then in the next step use (30)
and (33) to find the stationary saddle-point equilibrium
strategies f*N-1, g*N-1 at state i = N - 1, their corresponding
transition rate p*N-1 = mN-1,N (f*N-1, g*N-1) and the Riccati
solution ZN-1 . The process is iterated again by using ZN-1
in (30) for i = N - 2, and the obtained strategy pair
(f*N-2, g*N-2) is used in (33) to solve ZN-2 . Hence backward
induction is used to obtain Z1 and (f*1, g*1) .
Note that the coupling between (32), (33) and (29), (30)
demonstrates the interdependence between security at the
cyberlevel and the robustness at the physical level. The
holistic viewpoint toward these system properties is essential
in addressing the resilience of cyberphysical control
systems. The coupling between cyber and physical levels of
the system is not one directional but rather reciprocal. The
upward resilience from the physical level to the cyberlevel
results from the function ci while the downward resilience
from the cyberlevel to the physical level follows from the
dependence of mij on the cyberpolicies.
GAMES-IN-GAMES STRuCT uRE
The cross-layer, game-theoretic model captures the coupling
between the cyber and the physical layers of the
56 IEEE CONTROL SYSTEMS MAGAZINE » FEBRUARY 2015
system dynamics. In the framework, robustness of the
cyberphysical control system is studied under an H3 optimal
control model, while its security is studied using a
two-person zero-sum cybersecurity game. The control and
defense strategy designs are extended to incorporate postevent
system states, where resilient control and cyberstrategies
are developed to deal with uncertainties and events
that are not taken into account in pre-event robustness and
security designs. Under the assumptions made in Theorems
1 and 2, a secure, resilient, and robust control and
cyberstrategy pair (nCL, F) has to satisfy the general optimality
criteria (14), (15), and (17). In the linear quadratic
problem with cascading states, they are reduced to (32), (33),
(29), and (30). They are derived from the optimality criteria
of two dynamic games. One is the zero-sum differential
game for the H3 robust control design, and the other one is
the zero-sum stochastic game for equilibrium defense
policy. Due to the layering architecture and the time-scale
separation, the CSG can been seen as the one on top of the
PSG. The two games are coupled and exhibit a games-ingames
structure as illustrated in Figure 4. The outcome of
the PSG affects the cost structure of the CDG. In addition,
the solution to the PSG depends on the equilibrium solution
(F*, G*) from the CSG. Solutions to this game structure
define the tradeoff between robust and resilient control of
cyberphysical control systems.
One interesting aspect of the games-in-games structure is
that its solution is featured by zooming-in and zooming-out
operations. The zooming-out operation refers to the fact that
the solution of the PSG provides an input to the CSG, which
leads to a solution of the CSG. The zooming-in operation
refers to the reverse fact, that is, the PSG also affects the CSG.
As depicted in Figure 4, solutions to the coupled optimality
criteria precisely involve these two procedures. zooming in is
defined as the operation of passing the parameters from
higher level CSG to lower level PSG, and zooming out as the
operation of passing the parameters from the lower-level
PSG to the higher level CSG. A sequence of structured
zooming-in and zooming-out operations is observed in the
linear-quadratic problem with cascading states. The procedure
for finding the solution starts with finding ZN-1 using
(33) and then zooming out to the CSG to find (v*b (N - 1), fi, gi) .
This is followed by zooming in to the PSG again and find
ZN-2 . The zooming-in and zooming-out operations alternate
until reaching the initial state i = 1.
A Numerical Example
Consider the following two-state linear system that arises
from a single-machine infinite bus power system linearized
around its operation point [18]. Let x ! R3 be the state
vector that includes the power angle, the relative speed,
and the active power delivered by the generator. Let u ! R3
be the control variable that determines the amplifier of the
generator. At the normal operating state i = 1, its dynamics
are described by
xo = A1 x + B1 u + D1 w,
A1 = >
B1 = >
0 1 0
0 -0.625 -39.2699 H,
-0.156627 1.65884 -0.738602
0 0
0 H, D1 = >0H.
-0.271287 1
(34) in Theorem 4 are used to obtain the discounted value functions
v*b (i), i = 1, 2, with the discount factor chosen to be
b = 1, and yield V2 = 7.2075 # 104 independent of the
parameter p. Hence, v*b (2) = V2 and v*b satisfies the following
fixed-point equation:
v*b (1) = val"H - v*b (1) G,,
(36)
where
where
With an unanticipated fault caused by a cyberattack at the
rate m12, the system is compromised and its dynamics at the
failed state i = 2 are given by
xo = A2 x + B2 u + D2 w,
(35)
A2 = >
B2 = >
0 1 0
0 -0.625 -39.2699 H,
-0.0691878 0.960155 -0.407174
0 0
0 H, D2 = >0H.
-0.119837 1
The design strategy based on the linear quadratic criterion
described above could be used here, by choosing the
weighting matrices
1000 0 0
Q1 = Q2 = > 0 1 0 H, R1 = 10, R2 = 1,
0 0 10
where the weights of 1000 are used in Q1 and Q2 to emphasize
the willingness to use more control in a post-attack state.
The muij, i, j = 1, 2, take the following parameterized form:
mu12 = p, mu11 =-p, mu21 = mu22 = 0, where it has been assumed
that the operation after the attacker cannot be immediately
recovered. At the cyberlayer, the administrator can take
two actions, that is, to defend (l1 = D) and not to defend
(l2 = ND) . The attacker can also take two actions, that is, to
attack (a1 = A) or not to (a2 = NA) . The parameter p determines
the probability transition law with respect to pure
strategies and its values are tabulated as
A NA
D 0.1 0.05 .
ND 0.95 0.05
In the above table, a higher transition rate has been
attached to a failure state if the attacker launches an attack
while the cybersystem does not have proper measures to
defend itself. On the other hand, the probability is lower if
the cybersystem can defend itself from attacks. In the above
table, a base transition rate of 0.05 has been assumed to capture
the inherent reliability of the physical system without
exogenous attacks. The optimality criterion (28) and GAREs
H = ;18..44389667 ## 110044 00..99999944 ## 110044E,
0.1 0.05
G = ;0.95 0.05E,
where val is the value operator for a matrix game [44], [45].
Using value iteration, it is possible to compute
v*b (1) = 1.3087 # 104, and the corresponding stationary saddle-point
strategy f* = [1, 0]l, g* = [0, 1]l, which is a pure
strategy leading to an optimal value of p = 0.05. The stationary
saddle-point equilibrium strategy informs that the
defender should always be defending and the attacker
should not be attacking. At p = 0.05, the physical layer
robust feedback control at each state i is obtained by
uF (t, x, 1) =-(R1) -1 B1 < Z1, uF (t, x, 2) =-(R2) -1 B2 < Z2,
399.3266 31.8581 -162.2334
Z1 = > 31.8581 5.7083 -15.2963 H,
-162.2334 -15.2963 149.7459
where
and
where
and
2.8512 0.1066 -2.8575
Z2 = > 0.1066 0.0345 -0.1041H,
-2.8575 -0.1041 4.1506
and the optimum performance index is c*3 = 8.5.
CASE STu DY: DEf ENSE AGAINST
DENIAL-Of-SER vICE ATTACk
The games-in-games principle for the special case of the
linear-quadratic problem with cascading failures has been
applied to study the resilience of the power energy system
in [18]. The principle can be further extended to discretetime
systems where the physical layer game is a discretetime
minimax design problem with perfect state
measurements and the cyberlayer game is a discrete-time
stochastic Markov game. In parallel to the results developed
for continuous-time systems, a similar set of coupled
equations for discrete-time systems can be developed.
Interested readers can refer to [13] and [21] for results on the
FEBRUARY 2015 « IEEE CONTROL SYSTEMS MAGAZINE 57
discrete-time minimax design problem with perfect and
imperfect state measurements. To further illustrate this, a
case study of denial-of-service (DoS) attack is discussed
below, which can cause delays and congestion in the communication
channel of the cyberphysical systems.
Control System Model
A networked control system is vulnerable to different types
of cyberattacks, including false data injection, DoS, and
sensor node capture and cloning attack, as depicted in
Figure 5. Here, the games-in-games principle is used to
study a class of DoS attacks on control systems. The controlled
plant under DoS attacks is described by a discretetime
model for computational convenience
xk+1 = Axk + B2 uc,k + B1 ~k,
' zk = Dxk,
(37)
where xk ! Rn and uc,k ! Rm are, respectively, the state variable
and the control signal received by the actuator, ~k is the
disturbance belonging to l2 [0, 3) . A, B1, B2, and D are matrices
with appropriate dimensions. The measurement with
randomly varying communication delays is described by
+
#
A1
Controller
A2
u
A3
A2
IDS
C-A Delay di
yc
S-C Delay bi
IDS
f iGure 5 Many components of a networked control system are vulnerable to cyberattacks,
including the controller, the physical plant, and the communication networks [51]. In the diagram,
dotted blocks constitute the cyberlayer of the system while blocks with solid lines are
components at the physical layer. A1 and A4 represent direct attacks against the actuators or
the plant. A2 is the denial of service attack, where the controller is prevented from receiving
sensor measurements and the actuator from receiving control signals. A3 and A5 represent
deception attacks, where the false information uy ! y and uu ! u is sent from sensors and controllers.
Intrusion detection systems (IDSs) are detection devices used to defend the control
system from intruders but may cause C-A delay between controller (C) and actuator (A) and/or
S-C delay between sensor (S) and controller (C). The probabilities of incurring a one time-step
delay are denoted by parameters di and bi, which depend on the cyberstate i. An IDS is configured
optimally as a tradeoff between physical layer control system performance and cyberlevel
security enhancement.
58 IEEE CONTROL SYSTEMS MAGAZINE » FEBRUARY 2015
yk = Cxk,
)yc,k = (1 - di ) yk + di yk-1,
where yc,k ! Rp is the measured output and yk ! Rp is the
actual output. i ! S := {i1, i2, f, is} is the state space of the
cybersystem. The stochastic variable di is distributed
according to a Bernouli distribution:
dri := Pr {di = 1} = E {di},
Pr {di = 0} = 1 - E {di} = 1 - dri .
When di = 1, the measured output is yc,k = yk-1, that is, the
measured output has a one-step time delay. When di = 0,
the measured output is yc,k = yk, that is, there is no delay
between the measured output and the actual system output.
An observer-based control strategy takes the form of
)
xtk+1 = Axtk + B2 uc,k + Li (yc,k - yrc,k),
yrc,k = (1 - di) Cxtk + di Cxtk-1,
)
uk = Ki xtk,
uc,k = (1 - bi) uk + bi uk-1,
(38)
(39)
(40)
(41)
uc
A5
where uk ! Rm is the control signal generated by the controller
and uc,k is the signal received by the actuator. Ki ! Rm#n
and Li ! Rn#p denote the controller
gains and observer gains that
Physical Layer are to be designed. The stochastic
Cyber Layer variable bi, mutually indepenA4
tdreibnuttoefddi,wishiatleso saeBquerennocuelliwdiitshexpected
value bri . Note that the
Physical y sensor-to-controller (S-C) delay
System is described by the situation that
di = 1, and the controller-toactuator
(C-A) delay is described
by bi = 1.
Intrusion Detection Systems
IDSs are deployed in communication
networks for detecting unauthorized
system access. They are
passive devices that receive and
evaluate information sent over a
network against a set of signatures.
IDS signatures have been
developed for most published
vulnerabilities and for potentially
dangerous activity in common IT
protocols. The C-A and S-C delays
depend on the configurations of
the IDSs. A configuration providing
high information assurance
can result in significant delays for
control system applications since
a large number of signatures have
to be checked for each incoming
Uncertainties from the cybersystem are often unanticipated and more
catastrophic for control systems in terms of their high impact and low effort
as compared to those from the physical world.
packet. The configuration of IDSs is not a trivial task.
The current version of the Snort IDS, for example, has
approximately 10,000 signature rules located in 50 categories.
Each IDS also comes with a default configuration
to use when no additional information or
expertise is available. It is not trivial to determine the
optimal configuration of an IDS because of the need to
understand the quantitative relationships between a
wide range of analyzers and tuning parameters.
For industrial control systems, a set of SCADA IDS
signatures that parallel Snort rules for enterprise IT
systems have been designed by Digital Bond's Quickdraw,
which leverages the existing IDS equipment by
developing signatures for control system protocols,
devices, and vulnerabilities [50]. In Figure 6, a typical
SCADA IDS rule is illustrated, which is used to detect
a buffer overflow attack. The rule is specifically
designed for Siemens Tecnomatix FactoryLink software,
which is used for monitoring, supervising, and
controlling industrial processes. FactoryLink is commonly
used to build applications such as HMI systems and SCADA
systems. The logging function of FactoryLink is vulnerable
to a buffer overflow caused by the usage of vsprintf with
a stack buffer of 1024 B. The vulnerability can be exploited
remotely in various ways like the passing of a big path or
filter string in the file related operations [50].
The goal of the network administrator is to configure an
optimal set of detection rules to protect the cybersystem
from attackers. To model the interaction between an
attacker and a defender, a dynamic game approach is used.
Let L* be a finite set of possible system configurations in
the network and A be the finite action set of the attacker.
The mixed strategies f (k) and g (k) are defined on the action
spaces L* and A , respectively.
The distributions of random variables di and bi are
dependent on the states and attack and defense mechanism
in the cyberlayer. Let H ! RN#M and W ! RN#M be two
state-dependent matrices whose entries Hij and Wij reflect
the S-C and C-A delays for different attack and defense
action pairs (Fi, aj) . The parameters of the Bernoulli random
variables are determined by mixed strategies fi, gi as
dri := fiT H (i) gi,
bri := fiT W (i) gi .
The cybersystem transitions between different states
and its transition probabilities
alert tcp any any -> any 7580 (msg:”ETPRO SCADA
Siemens Tecnomatix FactoryLink CSService GetFile
path Buffer Overflow”; flow:to_server, established;
content:“LEN|00|”; depth:4; byte_test:4,>,
1028,0,little; content:”|99|”; distance:8; within:1;
content:”|99 00 00 00 08 00 00 00 02 06|”; distance:
0; byte_test:4,>,1024,0,big; classtype:attempteduser;reference:url,digitalbond.com/tools/quickdraw/
vulnerability-rules; sid:1111675; rev:1;)
f iGure 6 A supervisory control and data acquisition (SCADA) intrusion
detection system rule to detect CSService CSMSG GetFile buffer overflow
in a Siemens Tecnomatix FactoryLink: Siemens Tecnomatix FactoryLink
software is used for monitoring, supervising, and controlling
industrial processes. FactoryLink can be used to build applications such
as human-machine interface systems and SCADA systems. The logging
function of the software is vulnerable to a buffer overflow caused by
vsprintf with a stack buffer of 1024 B. An attacker can exploit the
vulnerability remotely to cause application crash and obtain illegitimate
access to arbitrary memory.
P (il (n + 1) i (n), aj, Fi), il (n + 1),
i (n) ! H,
are dependent on the defense and attack action pair (Fj, a j)
at time n, and
/ P (il i (n), Fi, aj) = 1.
il ! H
Cross-Layer Control Design
The H3 index is the expectation over fi and gi for a given
i. Without loss of generality, let x0 = 0; then
3 3
Ef(i),g(i) ' / { zk 2}1 < ci2 / { ~k 2},
k =0 k =0
(42)
for all i ! H. The goal of the physical layer control design is
to find optimal Ki, Li, i ! S. The theorem below indicates
how to convert the conditions satisfying the H3 index into
linear matrix inequalities (LMIs) that are easy to solve
numerically using available tools.
Theorem 5 [21]
Given scalars ci > 0 and a strategy pair (fi, gi) for all i ! H,
the hybrid model described by (37)-(41) is exponentially
mean-square stable and the H3-norm constraint (10) is
achieved for all nonzero ~k if there exist positive definite
matrices P1i1 ! Rm# m, P2i2 ! R(n-m)# (n-m), Si1 ! Rn# n and P2i !
FEBRUARY 2015 « IEEE CONTROL SYSTEMS MAGAZINE 59
al Gorithm 1 an algorithm for coupled design.
Given: H(i) and W(i) for all i ! H, Fi ! L*, a j ! A,
Output: Ki and Li for all i ! H; F*s and G*s.
1) Initialization:
2) Initialize v0b and b = 0.5.
3) Iterative update:
4) while ( vhb+1 -vhb > f ) do
5) Solve the convex optimization problem (46) and obtain
C(i).
6) Calculate the cost matrix R(i) := [Rij (i)] using
Rij (i) = Cij (i) +b / P(il | i,Fi,a j)vh(il).
il !H
(47)
7) Find the value vhb+1(i) of the matrix game R(i) using the
following linear program
(LPMG) vhb+1(i) = max uyl1m
u
y
s.t RT (i) uy # 1n
uy $ 0.
8) end while
9) Obtain F*s using f*i = uyvb(i) and solve the dual problem of
(LPMG) to get G*s and gi
*
10) Use Theorem 2 to obtain the controller gain and the
observer gain for all i ! H with
Ki = VR-1P1i1-1RVT Mi, Li = S1i-1Ni.
Rn#n and Si2 ! Rn#n, and real matrices Mi ! Rm#n, Ni ! Rn#p
such that
P1i := U1T P1i1 U1 + U2T P2i2 U2,
where U1 ! Rm#n and U2 ! R(n-m)#n satisfy
;UU12EB2 V = ;0E,
R
R = diag {v1, v2, f, vm},
and vi, i = 1, 2, f, m, are eigenvalues of B2 . In addition, the
controller gain and observer gain satisfy the following LMIs:
Ki = VR-1 P1i1-1 RVT Mi,
Li = Si1-1 Ni,
Pi = ;PPii1211 Pi22E 1 0,
*
where
SRP2i - P1i
S 0
Pi11 = SS 0
S 0
ST 0
RS-P1i *
S 0 -Si1
Pi22 = SS 0 0
S 0 0
TS 0 0
* * *
S2i - S1i * *
0 -P2i *
0 0 -S2i
0 0 0
* * * WV
* * * W
-P1i * * WW,
0 -Si1 * W
0 0 -IWX
Pi21 = =PPii2211 ((12,, 11)) PPii2211 ((12,, 22))G,
* WV
* W
* WW,
* W
-c2i IWX
60 IEEE CONTROL SYSTEMS MAGAZINE » FEBRUARY 2015
(43)
(44)
(45)
Pi21 (1, 1) = =P1i A + (1 - bri) B2 Mi
0
-(1 - bri) B2 Mi
Si1 A - (1 - dri) Ni C (i)G,
Pi21 (1, 2) = =br i B02 Mi --drbri NiBi2CM(ii) PSi11iBB11G,
ai1 B2 Mi -ai1 B2 Mi
Pi21 (2, 1) = >ai2 Ni C (i) 0
D 0
H,
-ai1 B2 Mi ai1 B2 Mi 0
Pi21 (2, 2) = >-ai2 Ni C (i) 0 0H,
0 0 0
ai1 = [(1 - bri) bri] 1/2,
ai2 = [(1 - dri) dri] 1/2 .
Note that (43) and (44) in Theorem 5 lead to a convex
optimization problem
(46)
cti := PSi111>>00,,SPi2i2>2 >0,0M,Pii2, N>i0
min ci
i
subject to (42) .
Since ci is influenced by the cyberstate and strategy, it is
actually dependent on the triple (i, f (i), g (i)) . Let
C (i) ! RN#M be the performance matrix with its entry Cij (i)
corresponding to the physical layer H3 performance index
under the action pair (Fi, a j) . cti can be seen as the value of
the mapping:
cti = fiT C (i) gi .
The coupled design here means that the cyberdefense
mechanism takes into account the H3 index, and the H3
optimal controller is designed with dri = f*iT H (i) gi* and
bri = f*iT W (i) gi* . Algorithm 1 is proposed for the coupled
design. The algorithm involves a value iteration for computing
the stationary mixed saddle-point equilibrium for
the stochastic game, in which a linear program for matrix
games (LPMG) is solved at each step. For computation of
the saddle-point equilibrium using linear programming,
see “Linear Programming for Computing the Saddle-Point
Equilibrium.” Since the game here is zero-sum and finite,
the value iteration method converges to stationary saddlepoint
equilibrium strategies. Readers interested in a proof
of convergence of value iteration in zero-sum finite games
can refer to [44] and [45]. The algorithm also invokes the
computational tools for solving a set of LMIs for obtaining
the H3 robust controller in the form of (40) and (41) that
achieves optimal control system performance.
A Numerical Example
An uninterrupted power system (UPS) model is used to
illustrate the design procedures. A UPS usually provides
uninterrupted, high quality, and reliable power for vital
loads, such as life support systems, data storage systems, or
emergency equipment. Thus, the resilience and robustness
A cyberphysical control system can be conceptually divided into six layers:
physical, control, communication, network, supervisory, and management.
of the UPS are essential. An integrated design of the optimal
defense mechanism for IDSs and the optimal control
strategy for a pulse-width modulation (PWM) inverter is
performed such that the output ac voltage can maintain its
desired setting under the influence of DoS attacks. Let the
system parameters be
0.9226 -0.6330 0
A = > 1.0 0 0H,
0 1.0 0
0.5 1
B1 = > 0 H, B2 = >0H,
0.2 0
D = 60.1 0 0@,
C = 623.738 20.287 0@.
For the cyberlayer, two states are considered: a normal state
i1 and a compromised state i2 . When there are no attacks
and the system is in normal state, the communication network
is taken to be delay free, that is, dri = bi = 0. The IDS
system contains two libraries l1, l2 for defending against two
attacks a1, a2 . Library l1 is used for detecting a1 whereas
library l2 for a2 . Let A = {a1, a2}, L* = {F1, F2}, where F1 is the
configuration where l1 is loaded and F2 is the configuration
where l2 is loaded. Figure 7 illustrates the performance of
IDS configurations under different attack scenarios.
a1
a2
F1
F2
f iGure 7 An example to illustrate the necessity of different intrusion
detection system (IDS) configurations. Library l1 is used to
detect a1 while library l2 is used to detect a2. Configurations
F1 := {l1} and F2 := {l2} are used to detect a sequence of attacks
composed of a1 and a2. Each configuration leads to a different
physical layer probability of delay in S-C and C-A communication
channels. The diagram shows IDS performance under four action
pairs (a1,F1),(a1,F2),(a2,F1), and (a2,F2) in a two-by-two matrix
style, where the row corresponds to configurations, while the
column refers to different attack actions. A circle refers to an
attack. A box refers to a configuration. A successful defense
thwarts an attack. An X denotes a successful defense that prevents
the attack from propagating further. The attacks a1 and a2
can be successfully detected in the case of (a1,F1) and (a2,F2),
respectively. The attacks will penetrate the system for the scenarios
corresponding to (a1,F2) and (a2,F1).
Linear Programming for Computing Saddle-Point Equilibrium
L each other by the relation of which can be found in [35].
et A and B be two (m # n)-dimensional matrices related to MSSPE. The following proposition captures this result, a proof
A = B +c1m1ln,
(S3)
where 1m stands for the m-dimensional column vector whose
entries are all ones and c is some constant. Denote by Vm(A)
and Vm(B) the saddle-point values in mixed strategies for matrix
games A and B, respectively. Then
1) every mixed strategy saddle-point equilibrium (MSSPE)
for matrix game A also constitutes a MSSPE for the matrix
game B, and vice versa
2) Vm(A) = Vm(B) +c.
Matrix games that satisfy (S3) are strategically equivalent
matrix games. For a given matrix game A, a strategically equivalent
matrix game can be found with all entries positive by adding
a constant c.
Based on this fact, the complete equivalence between a
matrix game and a linear program (LP) is used to compute its
PROPOSITION S1
Given a zero-sum matrix game described by the m # n matrix
A, let B be another matrix game (strategically equivalent to A),
obtained from A by adding an appropriate positive constant to
make all its entries positive. Introduce the two LPs:
Primal LP: max yl1m such that Bly # 1n, y $ 0,
Dual LP: min zl1n such that Bz $ 1m, z $ 0,
with their optimal values (if they exist) denoted by Vp and Vd,
respectively. Then
1) Both LPs admit solutions, and Vp = Vd = 1/Vm(B).
2) If (y),z)) solves matrix game B,y)/Vm(B) solves the primal
LP, and z)/Vm(B) solves the dual LP.
3) If uy) solves the primal LP, and uz) solves the dual LP,
the pair (uy)/Vp,uz)/Vd) constitutes a MSSPE for the matrix
game B, and hence for A, and Vm(B) = 1/Vp.
FEBRUARY 2015 « IEEE CONTROL SYSTEMS MAGAZINE 61
6
N
f iGure 8 The value iteration method for finding the value of the
zero-sum stochastic game using the iterative steps 4-8 in Algorithm
1. The game values at states i1 and i2 are found to be
v0.5 = [0.3370 0.5299] T. The optimal mixed strategies are f*i1 =
[0.4273 0.5726] T, f*i2 = [0.2329 0.7671] T, g*i1 = [0.5726 0.4273] T,
and g*i2 = [0.7671 0.2329] T.
i(n) = 1
i(n) = 2
No Attack
0
20
40
60
80 100 120 140 160 180 200
k
f iGure 9 The minimax optimal controller design for the uninterrupted
power system. The observer and the controller gains at state i1 are
Li1 = [0.0283 0.0296 0.0125] T, and Ki1 = [- 0.9357 0.6424 0],
respectively, and for i2, the gains are Li2 = [- 0.7075
0.7663 - 0.0003] T, and Ki2 = [0.0142 0.0238 0.0118]. The controller
signal at the compromised state has higher magnitude than the
one at state i1. Under no attack (that is, the S-C and C-A delays are
zero), the optimal gains are found to be L = [0.0658 0.0421 0.0108] T,
K = [- 0.9226 0.6330 0].
The following tables describe the payoff matrix pairs
(H (i), W (i)) that correspond to the scenarios in Figure 7. At
cyberstate i1,
a1
a2
H (i1) = W (i1) = F1 0.01 0.05 ,
F2 0.03 0.01
and at state i2,
respectively.
62 IEEE CONTROL SYSTEMS MAGAZINE » FEBRUARY 2015
1
0.9
0.8
0.7
0.5
0.4
5
N v.00.6
0.3
0.2
0.1
0
)
k
(
u
-0.1
-0.2
-0.3
-0.4
1
2
3
4
5
7
8
9
10
11
0
5
10
15
20
25
30
35
v0.5(i1)
v0.5(i2)
n
i
3.5
2.5
1.5
0.5
4
3
2
1
0
i1
i2
n
f iGure 10 The evolution of cyberstate of the system under the
saddle-point configuration policy. The cybersystem stochastically
switches between two cyberstates based on the saddle-point
mixed strategy of the cybergame.
and the matrix of transitions between states under different
action pairs (Fi, a j), i = 1, 2, j = 1, 2, is
a1 a2
F1 (1, 0) (0, 1) .
F2 (0, 1) (1, 0)
When IDSs are configured in a correct way to defend
against attacks, the system remains safe at its normal state
i1 . When attacks cannot be defended against by the IDS,
the system transitions to a failure state i2 . Likewise, at
cyberstate i2 the transition matrix takes the same form as
in state i1 . It captures the fact that the system can be recovered
manually if intrusions are detected correctly; otherwise,
the system remains in failure state i2 .
a1 a2
H (i2) = W (i2) = F1 0.06 0.1 .
F2 0.08 0.06
The cost/reward table lists the H3 performance index
under action pairs (Fi, a j), i = 1, 2, j = 1, 2. At state i1,
a1 a2
F1 0.0994 0.1641 ,
F2 0.1232 0.0994
a1 a2
F1 0.1961 0.8084 ,
F2 0.3148 0.1961
1500
k
500
1000
2000
2500
3000
0
1000 2000 3000 4000 5000 6000 7000
k
f iGure 12 The performance of the dynamical system under the
codesigned controller when it switches between two cyberstates.
With a sinusoidal input into the physical layer system and the
cyberswitching depicted in Figure 10, the output from the physical
system is observed. At the failure state, the system has a high
attenuation rate than at normal state.
0.4
0.3
0.2
0.1
0
)
k
(
z -0.1
-0.2
-0.3
-0.4
-0.5
0
f iGure 11 The performance when a conventional H3 optimal controller
is used to control the physical dynamical system. The blue
curve is the system output under state i2 whereas the red curve is
the output under state i1. The physical-layer system performance
switches randomly between the two cyberstates. The performances
are shown for sinusoidal inputs for each cyberstate. In
comparison to Figure 12, the resilient control allows the system to
be more secure with less probability of being in a compromised
state and more robust even when the system is compromised.
Using Algorithm 1, the game values with b = 0.5 at
states i1 and i2 are v0.5 = [0.3370 0.5299] T. The optimal
mixed strategies are f*i1 = [0.4273 0.5726] T, f*i2 = [0.2329
0.7671] T, g*i1 = [0.5726 0.4273] T and g*i2 = [0.7671 0.2329] T .
Figure 8 shows the iterative process to find the value of the
game in Algorithm 1. It can be seen that the value function
of the zero-sum stochastic game converges within ten steps
using the value iteration method. It can be seen from the
obtained equilibrium mixed strategies that, at a compromised
state, more expensive defense mechanisms are used
by the system, which leads to recovery of its normal operation.
Figure 9 shows the minimax control signal under minimax
closed-loop optimal control. The controller signal at
the compromised state has a higher magnitude than at the
normal state. The system tends to spend more control effort
to recover the system from instability after attacks. Figure
10 shows the evolution of cyberstates under the saddlepoint
configuration policy and H3 optimal control. The
cybersystem stochastically switches between two cyberstates
based on the saddle-point mixed strategies. At the
equilibrium strategies, the occurrence of a compromised
state is less frequent than the normal operating state. Figure
11 compares the steady-state performance of a conventional
H3 design and its performance under resilient control
design. In the failure state, the system has a higher attenuation
rate than the one that occurs at the normal state due to
the larger control effort (seen in Figure 9). This is how the
system is designed to recover from its failure mode. Figure
12 shows the stable oscillation of the physical system under
switching between two cyberstates i1 and i2 . Figure 13
0.15
0.1
0.05
0
k
z-0.05
-0.1
-0.15
-0.2
0.15
0.1
0.05
0
)
k
(
z-0.05
-0.1
-0.15
-0.2
0
i1
i2
i(n) = 1
i(n) = 2
No Attack
20 40 60 80 100 120 140 160 180 200
k
f iGure 13 The H3 control result under different cyberstates. The
control input signal at state i1 has a lower magnitude than its
counterpart at state i2. The control system requires a higher control
effort at a compromised state as it is subjected to a higher
probability of S-C and C-A delays. Under no attack, the control
system experiences no delays, that is, di = bi = 0, and the control
effort is the minimum among the three cases.
shows the control action from the H3 optimal controller
for the physical layer under different cyberstates. Resilient
control keeps the system more often in a normal state,
and makes the system more robust even when the system
is compromised.
Su MMARY AND CONCLu SION
With the increasing integration of information technologies
into industrial systems and networks, such as the
FEBRUARY 2015 « IEEE CONTROL SYSTEMS MAGAZINE 63
To provide performance guarantees, control systems should be designed
to be inherently resilient, allowing them to self-recover from
unexpected attacks and failures.
power grid, robust and resilient control system design is
essential for assuring the robust performance of cyberphysical
control systems in the face of adversarial attacks.
This article has presented a hybrid game-theoretic framework
whereby the occurrence of unanticipated events is
modeled by stochastic switching, and deterministic uncertainties
are represented by the known range of disturbances.
The design of a robust controller at the physical
layer takes into account risks of failures due to the cybersystem,
while the design of the security policies is based on
its potential impact on the control system. The cross-layer
coupled design introduced in this article results in solving
a zero-sum differential game for robust control coupled
with a zero-sum stochastic game for the security policy.
The two games are intertwined and coupled together
through cyber and physical system variables. The solution
to the two coupled games requires a zooming-in process,
which uses variables from the cyberlevel to solve the physical
layer game, and a zooming-out process, which uses
physical system variables to solve the cyberlayer game. The
joint design results in a robust and resilient controller
switching between different modes for guaranteeing performance
in the face of unexpected events.
This article has presented a general class of system
models, where the physical system is described by nonlinear
ordinary differential equations, and the cybersystem is
captured by Markov models. The framework can be further
extended to other classes of systems including sampleddata
systems, systems with delayed measurements, and
model predictive control systems. The optimal design of
new classes of systems can follow the same games-in-games
principle discussed here and can be characterized by a new
set of optimality conditions. Interesting future research
includes the study of problems with stronger coupling, in
which control and defense strategies depend on both cyberstates
and physical states, and the development of advanced
computational tools to compute the control and defense
strategies. The article has also discussed offline computational
methods to compute the equilibria. In addition, learning
algorithms and adaptive mechanisms can be developed
within this framework to provide online adaptation to
changes, which will enhance the resilience of the system.
Study of a distributed network of cyberphysical systems is
another possible research direction. The networking effects
in the cybersystem can lead to performance interdependencies
of distributed physical layer control systems.
64 IEEE CONTROL SYSTEMS MAGAZINE » FEBRUARY 2015
Au THOR INf ORMATION
Quanyan Zhu (quanyan.zhu@nyu.edu) is an assistant professor
in the Department of Electrical and Computer Engineering
at New York University. He received the B.Eng. in
honors electrical engineering with distinction from McGill
University in 2006, the M.A.Sc. from the University of Toronto
in 2008, and the Ph.D. from the University of Illinois
at Urbana-Champaign in 2013. From 2013 to 2014, he was a
postdoctoral research associate in the Department of Electrical
Engineering, Princeton University. He is a recipient
of many awards including the NSERC Canada Graduate
Scholarship, the Mavis Future Faculty Fellowships, and the
NSERC Postdoctoral Fellowship. He spearheaded the INFOCOM
workshop on Communications and Control on Smart
Energy Systems and the Midwest Workshop on Control and
Game Theory. His current research interests include optimal
control, game theory, reinforcement learning, network security
and privacy, resilient control systems, and cyberphysical
systems. He is a Member of the IEEE. He can be contacted at
LC200A, 5 MetroTech Center, Brooklyn, NY 11201 USA.
Tamer Bas¸ar is with the University of Illinois at UrbanaChampaign,
where he holds the positions of Swanlund Endowed
Chair, Center for Advanced Study Professor of Electrical
and Computer Engineering; research professor at the
Coordinated Science Laboratory; and research professor
at the Information Trust Institute. He received the B.S.E.E.
from Robert College, Istanbul, and the M.S., M.Phil, and
Ph.D. from Yale University. He is a member of the U.S. National
Academy of Engineering, a Life Fellow of IEEE, and
a fellow of International Federation of Automatic Control
(IFAC) and the Society for Industrial and Applied Mathematics.
He has served as president of IEEE Control Systems
Society (CSS), the International Society of Dynamic
Games (ISDG, and the American Automatic Control Council
(AACC). He has received several awards and recognitions
over the years, including the highest awards of IEEE
CSS, IFAC, AACC, and ISDG, and a number of international
honorary doctorates and professorships. He has over 600
publications in systems, control, communications, and dynamic
games, including books on noncooperative dynamic
game theory, robust control, network security, wireless
and communication networks, and stochastic networked
control. He is on editorial boards of several journals and is
editor of several book series. His current research interests
include stochastic teams, games, and networks; security;
and cyberphysical systems.
REf ERENCES
[1] S. Gorman. (2009, Apr. 8). Electricity grid in U.S. penetrated by
spies. Wall Str. J. [Online]. Available: http://online.wsj.com/article/
SB123914805204099085.html
[2] B. Krebs. (2008, June 5). Cyber incident blamed for nuclear power plant
shutdown. Washington Post. [Online]. Available: http://www.washingtonpost.com/wp-dyn/content/article/2008/06/05/AR2008060501958.html
[3] S. Greengard, “The new face of war,” Commun. ACM, vol. 53, no. 12, pp.
20-22, Dec. 2010.
[4] R. McMillan. (2010, Sept. 16). Siemens: Stuxnet worm hit industrial
systems. [Online]. Available: http://www.computerworld.com/s/article/
print/9185419
[5] L. Gunderson and C. S. Holling, Panarchy: Understanding Transformations
in Human and Natural Systems. Washington, D.C.: Island Press, Dec. 2001.
[6] B. Walker, D. Salt, and W. Reid, Resilience Thinking: Sustaining Ecosystems
and People in a Changing World. Washington, D.C.: Island Press, Aug. 2006.
[7] J. P. Kotter, “Accelerate!” Harv. Bus. Rev., vol. 90, no. 11, pp. 45-58, Nov.
2012.
[8] E. Hollnagel, D. D. Woods, and N. Leveson, Resilience Engineering: Concepts
and Precepts. Farnham, U.K.: Ashgate Publishing, Sept. 2006.
[9] E. Hollnagel, J. Pariès, D. D. Woods, and J. Wreathall, Resilience Engineering
in Practice: A Guide Book. Farnham, U.K.: Ashgate Publishing, Jan. 2011.
[10] C. Rieger, D. Gertman, and M. McQueen, “Resilient control systems:
Next generation design research,” in Proc. 2nd Conf. Human System Interactions,
2009, pp. 632-636.
[11] C. Rieger, “Notional examples and benchmark aspects of a resilient
control system,” in Proc. 3rd Int. Symp. Resilient Control Systems, 2010, pp.
64-71.
[12] K. Zhou and J. Doyle, Essentials of Robust Control, 1st ed. Englewood
Cliffs, NJ: Prentice-Hall, 1997.
[13] T. Bas¸ar and P. Bernhard, H-Infinity Optimal Control and Related Minimax
Design Problems: A Dynamic Game Approach, 1st ed. Switzerland: Birkhäuser,
1995.
[14] M. Manshaei, Q. Zhu, T. Alpcan, T. Bas¸ar, and J.-P. Hubaux, “Game
theory meets network security and privacy,” ACM Comput. Surv., vol. 45,
no. 3, pp. 1-39, June 2013.
[15] T. Alpcan and T. Bas¸ar, Network Security: A Decision and Game Theoretic
Approach. Cambridge, U.K.: Cambridge Univ. Press, 2011.
[16] D. Wei and K. Ji, “Resilient industrial control system: Concepts, formulation,
metrics, and insights,” in Proc. 3rd Int. Symp. Resilient Control Systems,
2010, pp. 15-22.
[17] W. Boyer and M. McQueen, “Ideal based cyber security technical metrics
for control systems,” in Proc. 2nd Int. Conf. Critical Information Infrastructures
Security, Berlin, Heidelberg: Springer-Verlag, 2008, pp. 246-260.
[18] Q. Zhu and T. Bas¸ar, “Robust and resilient control design for cyberphysical
systems with an application to power systems,” in Proc. 50th IEEE
Conf. Decision Control European Control, 2011, pp. 4066-4071.
[19] Q. Zhu and T. Bas¸ar, “A dynamic game-theoretic approach to resilient
control system design for cascading failures,” in Proc. 1st Conf. High Confidence
Networked Systems, CPSWeek, Beijing, China, Apr. 16, 2012, pp. 41-46.
[20] Q. Zhu, L. Bushnell, and T. Bas¸ar, “Resilient distributed control of
multi-agent cyber-physical systems,” in Proc. Workshop Control Cyber-Physical
Systems, Baltimore, MD, Mar. 20-21, 2013, pp. 301-316.
[21] Y. Yuan, Q. Zhu, F. Sun, Q. Wang, and T. Bas¸ar, “Resilient control of
cyber-physical systems against denial-of-service attacks,” in Proc. 6th Int.
Symp. Resilient Control Systems, 2013, pp. 54-59.
[22] M. Ilic, “From hierarchical to open access electric power systems,” Proc.
IEEE, vol. 95, no. 5, pp. 1060-1084, 2007.
[23] Q. Zhu and T. Bas¸ar, “A hierarchical security architecture for the smart
grid,” in Smart Grid Communications and Networking, E. Hossain, Z. Han,
and H. V. Poor, Eds. Cambridge, U.K.: Cambridge Univ. Press, 2012, ch. 18.
[24] H. Zimmermann, “OSI reference model-The ISO model of architecture
for open systems interconnection,” IEEE Trans. Commun., vol. 28, no. 4, pp.
425-432, 1980.
[25] J. F. Kurose and K. W. Ross, Computer Networking: A Top-Down Approach,
6th ed. Upper Saddle River, NJ: Pearson Education, 2012.
[26] Q. Zhu, H. Tembine, and T. Bas¸ar, “Distributed strategic learning with
application to network security,” in Proc. American Control Conf., San Francisco,
CA, June 29-July 1, 2011, pp. 4057-4062.
[27] Q. Zhu, H. Tembine, and T. Bas¸ar, “Heterogeneous learning in zerosum
stochastic games with incomplete information,” in Proc. 49th IEEE
Conf. Decision Control, 2010, pp. 219-224.
[28] M. Fabro and T. Nelson, “Control systems cyber security: Defense in
depth strategies,” ISA Expo, Houston, TX, INL Tech. Rep. INL/CON-0712804,
2007.
[29] Q. Zhu, M. McQueen, C. Rieger, and T. Bas¸ar, “Management of control
system information security: Control system patch management,” in Proc.
Workshop Foundations Dependable Secure Cyber-Physical Systems, CPSWeek,
Apr. 2011, pp. 51-54.
[30] J. Eisenhauer, P. Donnelly, M. Ellis, and M. O'Brien, “Roadmap to secure
control systems in the energy sector,” Energ. Incorp., U.S. Dept. Energy
and the U.S. Dept. Homeland Secur., 2006.
[31] A. Dominguez-Garcia, J. Kassakian, and J. Schindall, “A generalized
fault coverage model for linear time-invariant systems,” IEEE Trans. Reliab.,
vol. 58, no. 3, pp. 553-567, 2009.
[32] A. Haidar and E. K. Boukas, “Robust stability criteria for Markovian
jump singular systems with time-varying delays,” in Proc. 47th IEEE Conf.
Decision Control, 2008, pp. 4657-4662.
[33] Z. Pan and T. Bas¸ar, “H-infinity control of large scale jump linear
systems via averaging and aggregation,” Int. J. Control, vol. 72, no. 10, pp.
866-881, 1999.
[34] T. Bas¸ar, “Minimax control of switching systems under sampling,” Int.
J. Control, vol. 25, no. 5, pp. 315-325, Aug. 1995.
[35] T. Bas¸ar and G. J. Olsder, Dynamic Noncooperative Game Theory (Classics
in Applied Mathematics), 2nd ed. Philadelphia, PA: Soc. Ind Appl. Math.,
1999.
[36] Q. Zhu and T. Bas¸ar, “Dynamic policy-based IDS configuration,” in
Proc. 48th IEEE Conf. Decision Control, Held Jointly with the 28th Chinese Control
Conf., 2009, pp. 8600-8605.
[37] Q. Zhu, H. Tembine, and T. Bas¸ar, “Network security configurations:
A nonzero-sum stochastic game approach,” in Proc. American Control Conf.,
2010, pp. 1059-1064.
[38] Q. Zhu, A. Clark, R. Poovendran, and T. Bas¸ar, “Deceptive routing
games,” in Proc. IEEE 51st Annu. Conf. Decision Control, 2012, pp. 2704-2711.
[39] A. Clark, Q. Zhu, R. Poovendran, and T. Bas¸ar, “Deceptive routing in relay
networks,” in Proc. Conf. Decision Game Theory Security (Lecture Notes in
Computer Science), J. Grossklags and J. C. Walrand, Eds. Berlin Heidelberg,
Germany: Springer-Verlag, 2012, pp. 171-185.
[40] Q. Zhu and T. Bas¸ar, “Feedback-driven multi-stage moving target defense,”
in Proc. Conf. Decision Game Theory Security (Notes in Computer Science).
Berlin Heidelberg, Germany: Springer-Verlag, 2013.
[41] Q. Zhu, H. Tembine, and T. Bas¸ar, “Hybrid learning in stochastic games
and its application in network security,” in Reinforcement Learning and Approximate
Dynamic Programming for Feedback Control (Computational Intelligence
Series), F. L. Lewis and D. Liu, Eds. Piscataway, NJ: IEEE Press, 2012,
ch. 14, pp. 305-329.
[42] B. Randell, P. Lee, and P. C. Treleaven. (1978, June). Reliability issues in
computing system design. ACM Comput. Surv. [Online]. 10(2), pp. 123-165.
Available: http://doi.acm.org/10.1145/356725.356729
[43] L. S. Shapley, “Stochastic games,” Proc. Natl. Acad. Sci., vol. 39, no. 10,
pp. 1095-1100, 1953.
[44] J. Filar and K. Vrieze, Competitive Markov Decision Processes, 1st ed. Berlin
Heidelberg, Germany: Springer-Verlag, 1996.
[45] T. E. S. Raghavan and J. A. Filar, “Algorithms for stochastic games-A
survey,” Methods Models Oper. Res., vol. 35, no. 6, pp. 437-472, 2003.
[46] O. Hernandez-Lerma and J. Lasserre, “Zero-sum stochastic games in
Borel spaces: Average payoff criteria,” SIAM J. Control Optim., vol. 39, no. 5,
pp. 1520-1539, 2000.
[47] S. Meyn and R. L. Tweedie, Markov Chains and Stochastic Stability, 2nd
ed. Cambridge, U.K.: Cambridge Univ. Press, Apr. 2009.
[48] O. do Valle Costa, M. Fragoso, and M. Todorov. (2012). Continuous-Time
Markov Jump Linear Systems (Probability and its applications). Berlin Heidelberg,
Germany: Springer-Verlag. [Online]. Available: http://books.google.
com/books?id=Lal5ECvti-0C
[49] J. Nash, “Equilibrium points in N-person games,” Proc. Natl. Acad. Sci.,
vol. 36, no. 1, pp. 48-49, 1950.
[50] D. Bond. (2012, Feb. 20). Quickdraw SCADA IDS. [Online]. Available:
http://www.digitalbond.com/tools/quickdraw/
[51] R. A. Kisner, “Cybersecurity through real-time distributed control systems,”
Oak Ridge Natl. Lab., Tech. Rep. ORNL/TM-2010/30, 2010, pp. 4-5.
[52] J. von Neumann, “Zur Theorie der Gesellschaftsspiele,” Math. Annalen,
vol. 100, no. 1, pp. 295-320, 1928.
FEBRUARY 2015 « IEEE CONTROL SYSTEMS MAGAZINE 65