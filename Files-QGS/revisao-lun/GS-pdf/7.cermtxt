IEEE TRANSACTIONS ON AUTOMATIC CONTROL, VOL. 60, NO. 12, DECEMBER 2015
3299
Risk-Sensitive Control Under Markov Modulated
Denial-of-Service (DoS) Attack Strategies
Getachew K. Befekadu, Member, IEEE, Vijay Gupta, Member, IEEE, and Panos J. Antsaklis, Fellow, IEEE
Abstract-We consider the problem of risk-sensitive stochastic
control under a Markov modulated denial-of-service (DoS)
attack strategy in which the attacker, using a hidden Markov
model, stochastically jams the control packets in the system.
For a discrete-time partially observed stochastic system with an
exponential running cost, we provide a solution in terms of the
finite-dimensional dynamics of the system through a chain of
measure transformation techniques. We also prove a separation
principle under which a recursive optimal control policy together
with a newly defined information-state constitutes an equivalent
completely observable stochastic control problem. Remarkably,
on the transformed measure space, the solution to the optimal
control problem appears as if it depends only on the sample-path
(or path-estimation) of the DoS attack sequences in the system.
Index Terms-Denial-of-service, information-state, measure
transformations, risk-sensitive control.
I. INTRODUCTION
Recently, an increasing emphasis has been placed on addressing
the problem of risk and vulnerability assessment to malicious cyberattacks
against critical infrastructure such as power grids and industrial
control systems (e.g., see [1]-[5] and references therein). The issue
of security in such critical sectors has now become as important as
technical (and also practical) design problems. As these critical infrastructures
become interconnected and more complex, solutions that
ensure security against malicious cyber-attacks will gain even more
importance. A systematic study of design approaches that provide
provable security against malicious cyber-attacks is a core area of current
cyber-physical systems research. In particular, since such cyberphysical
systems will couple control of critical infrastructure with
communication networks, there is an urgent need to study the impact
of cyber-attacks in control systems. Accordingly, there have appeared
many recent works that consider security requirements, attacks and
vulnerabilities on control systems, wireless sensor networks and IT
infrastructure (e.g., see [6]-[11] and references therein).
By modeling the attacker as inducing network disruptions at every
time step according to a Bernoulli process, Amin et al. [6] considered
the LQG control problem and Befekadu et al. [12] considered the
risk-sensitive control problem. In this work, we extend the attacker
model from a memoryless Bernoulli process to one that follows a
hidden Markov model and derive an optimal risk-sensitive control
policy under this class of attack strategies. Our choice of a risksensitive
cost function is motivated by its use in robust control and
Manuscript received October 15, 2013; revised August 31, 2014 and
February 26, 2015; accepted March 11, 2015. Date of publication March 27,
2015; date of current version December 1, 2015. This work was supported
in part by the National Science Foundation under Grant CNS-1035655 and
by the College of Engineering, University of Notre Dame. Recommended by
Associate Editor C. M. Lagoa.
The authors are with the Department of Electrical Engineering, University
of Notre Dame, Notre Dame, IN 46556 USA (e-mail: gbefekadu1@nd.edu;
vgupta2@nd.edu; antsaklis.1@nd.edu).
Digital Object Identifier 10.1109/TAC.2015.2416926
dynamic games, where this criterion has proved to be an effective tool
in mapping a priori knowledge of the system parameters to the cost
functional (e.g., see [13]-[18] for details on this subject). We would
also like to mention that the related problem of optimal control when
control packets are being erased by a communication channel has been
studied in networked control systems literature (e.g., see [19]-[23] and
references therein).
Our main technical tool is a chain of measure transformations that
allows us to consider the optimal control design problem merely on
the sample-path (or path-estimation) followed by the attacker. Initially,
we introduce a new equivalent probability measure that characterizes
the nature of DoS attack sequences relative to all existing random
processes in the system (i.e., relative to the original (or reference)
probability measure space on which all random variables were initially
defined). In this equivalent probability measure space, the DoS attack
sequences are independent over their observed values. Once this is
accomplished, we introduce another (or different) probability measure
transformation that separately characterizes the plant state and the
observation variables of the discrete-time partially observed stochastic
system. Specifically, this latter measure transformation is derived in
such a way as to make the plant state and observation sequences
independent while the other variables remained unaffected under it.
Finally, we combine these measure transformations to obtain a system
characterization in which the DoS attack sequences are independent
over their observed values; while the plant observation sequences
are mutually independent to the other measure valued processes in
the system. This characterization allows us to define an equivalent
information-state (and the corresponding adjoint measure valued process)
for the partially observed stochastic system (e.g., see [17], [24],
or [25] for additional discussions). Then, we can prove a separation
principle that separates the optimal control problem from the estimation
problem via this newly defined information-state. That is, the
recursive optimal control policy together with the newly introduced
information-state constitute an equivalent fully observable stochastic
control problem. It may be noted that such a separation principle is not
a priori obvious given the risk-sensitive cost function and the hidden
Markov model based attacker model. A preliminary version of this
technical note was presented in [26].
The rest of the technical note is organized as follows. In Section II,
we introduce some preliminary concepts and formulate the risksensitive
control problem under a Markov modulated DoS attack
model. Section III presents the main results-where an exact solution
for the optimal control problem is formally stated and the associated
recursive solution for the optimal cost value is derived. Finally,
Section IV provides concluding remarks.For the sake of completeness,
all proofs and a short description of Girsanov's theorem are included
in a supplementary document.
II. PROBLEM FORMULATION
In this section, we provide a framework for the problem of risksensitive
stochastic control under a Markov modulated DoS attack
model. We also describe the problem formulation and some of the
0018-9286 © 2015 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission.
See http://www.ieee.org/publications_standards/publications/rights/index.html for more information.
3300
IEEE TRANSACTIONS ON AUTOMATIC CONTROL, VOL. 60, NO. 12, DECEMBER 2015
Fig. 1. Typical malicious cyber-attacks in control systems ([6]).
assumptions on the Markov modulated DoS attack model that are
necessary for the development of our results.
A. The System Model
Let (Ω, F ) be a measure space which is equipped with a global or
full-information filtration {Fk}, k ∈ N, and let P(Ω) be the set of
probability measures on (Ω, F ) satisfying the usual hypotheses (e.g.,
see [27]).1 On this measure space, consider the following discrete-time
partially observed stochastic system:
xk+1 = Axk + γ(Zk+1)Buk + νk+1
yk+1 = Cxk + wk+1,
k = 0, 1, . . . , N − 1
(1)
where xk ∈ Rn is the state of the system, uk ∈ Rm is the control
input, yk ∈ Rp is the observation process (output) and γ(Zk) ∈ {0, 1}
is the DoS attack sequence that disrupts the control packets from
reaching the actuator where Zk is related to the internal state of
the attacker.2 Furthermore, we assume that the process noise νk and
measurement noise wk are mutually independent with normal densities
ϕ ∼ N (0, Σ) and φ ∼ N (0, Γ), respectively; and the covariances Σ
and Γ are assumed to be positive definite matrices. Fig. 1 shows typical
malicious cyber-attacks in control systems: A1 and A3 represent
integrity (or deception) type attacks, A2 and A4 are DoS type attacks,
and A5 is a direct physical attacks in the system. Other attack models
such as integrity type attacks or direct physical attacks can also be
considered. We remark that DoS attack is a common intrusion of cyberphysical
systems (e.g., see [6], [7], or [28]).
In the following, we assume that P ∈ P(Ω) and let Yk ⊂ Fk
denote a complete filtration which is generated by {yk}k∈N. We further
assume that the DoS attack sequences follow a Markov process dynamics
and are independent to the other random processes in the sysΔ
tem. The admissible controls U = U0, N = {uk}kN=−01 are Rm-valued
sequences and considered to be adapted process (or non-anticipating
process that depends only on the observed output sequences and the
sample-path of the DoS attack sequences).
Remark 1: We remark that an attacker, who may have (partial)
knowledge about the system with possibly different time-scale compared
to the system dynamics in (1), is probably difficult, but certainly
an interesting problem.
1Note that all random processes or random variables are defined on this
measure space and they are also assumed to be progressively measurable. Thus,
all results in this technical note are to be interpreted as almost surely (a.s.) with
respect to a probability measure from the set P(Ω).
2In Section II-A below, we provide the exact formulation of the Markov
modulated DoS attack model [cf. (9) and (10)].
In this technical note, we consider an exponential running cost with
quadratic function of the form
J (u) =
1
E exp
θ
θ
2
N−1
k=0
xkT M xk +γ(Zk+1)ukT Suk
+ xTN MN xN
(2)
where θ > 0 is the risk-sensitive parameter, uk ∈ U0,N is the admissible
control sequences; while E[.] denotes the expectation with respect
to a reference probability measure P ∈ P(Ω). Moreover, M (and
also MN ) and S are assumed to be positive semidefinite and positive
definite matrices, respectively.
B. Markov Modulated DoS Attack Model
In the following, we describe the nature of the DoS attack sequences
γ(·) and discuss some of the associated assumptions necessary for
the development of our main results. To this end, consider a process
{Yk}k∈N which is an Rd-valued Markov process with dynamics
Yk = Fk(Yk−1) + Wk
(3)
where Y0 is assumed to have a known initial distribution, {Fk(.)}k∈N
is a bounded Rd-valued measurable function and {Wk}k∈N is a
sequence of Rd-valued independent random variables with density
function {ψk(.)}k∈N.
Further, let {Zk}k∈N be a two-dimensional stochastic process with
a finite state-space S. Without loss of generality, we take the statespace
to be the standard basis in R2, i.e., S =Δ {e1, e2}. Moreover,
define the following nondecreasing family of σ sub-algebras F0Z∨Y =
σ{Z0, Y0, Y1} ⊂ F0 and FkZ∨Y = σ{Zl, Yl+1, l ≤ k, k ≥ 1} ⊂ Fk
(and also augmented by a set Fk having P -measure zero). We assume
that the process Z is a conditional Markov chain, i.e.,
P Zk = ej |FkZ−∨1Y
= P [Zk = ej |Zk−1, Yk]
= aj (Zk−1, Yk)
2
i=1
=
aji(Yk) Zk−1, ej ,
j = 1, 2
(4)
Δ
where ., . is the standard inner product on R2 and y → A(y) =
[aji(y)] : Rd → R2×2 is an FkZ∨Y measurable matrix function such
that for all y ∈ Rd the following conditions are satisfied:
0 < aji(y) < 1
2
i=1
aji(y) = 1,
i, j = 1, 2.
That is, the matrix function A(y) is a Markov (or row-stochastic)
matrix for all y ∈ Rd.
The following lemma, which follows directly from equations (3),
(4), and (5), will be stated without proof.
Lemma 1: The random process {Zk}k∈N, which assumes value
from the finite state-space S, has the following representation:
Zk = A (Fk(Yk−1)) Zk−1 + Vk
E[Vk|FkZ−∨1Y ] = 0.
where the process {Vk}k∈N is an FkZ∨Y -martingale increment, i.e.,
(5)
(6)
IEEE TRANSACTIONS ON AUTOMATIC CONTROL, VOL. 60, NO. 12, DECEMBER 2015
Next, we define a discrete-time counting process Nkr that counts
the number of times the process Z has been in state r up to time k
measurable
Nkr =
Zl, er
=
=
k
l=1
k
l=1
k
2
l=1 i=1
ar(Zl−1, Yl) + Mkr
ari(Yl) Zl−1, er + Mkr
(7)
where {Mkr} is an FkZ∨Y -martingale increment.
Note that the Markov process {Yk}k∈N is not observed directly, but
through another Rd-valued random process {QNkr }k∈N such that
P
QNkr ∈ dq, Zk = er
FkZ−∨1Y
= ar(Zk−1, Yk)λrk(Yk, q)dq (8)
where λrk(Yk, .) is a probability density function defined on Rd for
every q ∈ Rd.
Then, we construct a new random process using the following
relation:
mrk(dq) = Zk, er 1Q QNkr ∈ dq
= ar(Zk−1, Yk)λrk(Yk, q)dq + Ukr
where {Ukr} is an FkZ∨Y -martingale increment and 1Q(QNkr ∈ dq)
stands for an indicator function of the Borel set Q. Hence, the complete
filtration generated by this observation process, i.e., mrk(.), is given by
Mk = σ
mlr(E ), l ≤ k, r = 1, 2 and E ∈ B(Rd)
where E is a Borel set of B(Rd).
Finally, we can associate the evolution of the random process
{Zk}k∈N to another {γ(Zk)}k∈N process, where each γ(Zk) is a binary
random sequence (i.e., γ(Zk) ∈ {0, 1} with γ(Z0) = 0).3 Note that the
distribution for this process depends on the state of the hidden Markov
model, namely, the probability of its success changes with respect
to the Markov process. Specifically, we exploit this property for our
DoS attack model realization. Although, {γ(Zk)}k∈N is a sequence
of identically distributed binary random variables, they are not necessarily
ordinary Bernoulli processes since they are not independent
in the original probability measure space, i.e., (Ω, F , P ). Moreover,
the discrete-time counting process Nkr, which is given by (7), records
a particular event that has been followed and its measured information
equally serve for this process. Therefore, (9) and (10) effectively
provide an observation model (i.e., path-estimation) for the Markov
modulated random processes [cf. (12) below].
C. Problem Statement
The problem considered in this technical note is stated as follows:
Problem: Find an optimal control policy for the finite-horizon risksensitive
control problem under a Markov modulated DoS attack
model, i.e.,
(9)
(10)
V0 =
ess inf J (u)
u∈U0,N−1
=
ess inf
u∈U0,N−1
1
θ
E exp
θ
2
N−1
k=0
xkT M xk
+ γ(Zk+1)ukT Suk
+ xNN MN xN
. (11)
3Notice that we can always achieve this via a sequence of bijective or oneto-one
mapping functions. For instance, a bijective mapping γ(Zk) = [0, 1]Zk
where Zk ∈ S can generate a binary random sequence.
Here, we consider the DoS attack sequences as a Markov modulated
packet drops due to network jams induced by the attacker at each time
k with success probability γ(Zk) (see also the remark in footnote 3). In
general, this attack model AM(γ(Z.)) will have the following samplepath
sequence(s)
AM(γ(Z.)) =
γ(Z0), γ(Z1), . . . , γ(ZN ) .
We remark that the exponential running cost function weighted by
a risk-sensitive parameter θ highlights designers belief about system
uncertainty back to the scale of cost functional.4 For a risk-neutral
criterion, when θ is sufficiently close to zero, the risk-sensitive control
problem reduces to an LQG control problem (e.g., see Bertsekas [14]
for details).
III. MAIN RESULTS
In this section, we explicitly use the measure transformation technique
to derive the optimal control policy for the risk-sensitive control
problem under a Markov modulated DoS attack model. The key idea
is to introduce measure transformation technique under which the
observation and state variables become mutually independent along
the sample-path (or path-estimation) of the DoS attack sequences
in the system. This allows us to obtain recursive formulas for the
equivalent information-state and associated adjoint process based on
the observation history, the current control input and the samplepath
of the DoS attack sequences. Using this fact, we further derive
an implicit formula for optimal control policy (i.e., separated policy
which essentially combines estimation and control as a single problem)
via dynamic programming.
A. Change of Measure for the DoS Attack Model
Let P¯ ∈ P(Ω) and suppose the following random variables are
given on measure space (Ω, F ) under which the random variable Q is
not affected by the random variables Y , Z, and m:
(i) {Zk}k∈N is a sequence of i.i.d. random variable uniformly
distributed on the set S = {e1, e2}, i.e.,
P¯ Zk = er FkZ−∨1Y
= .
1
2
(ii) {Qk}k∈N is a sequence of i.i.d. random variable with probability
density function ς(.) on Rd such that
¯ Qk ∈ dq Zk = er, FkZ−∨1Y
P
= ς(q)dq.
(iii) {mrk}k∈N, r = 1, 2 are random measures on (Rd, B(Rd)) with
P¯ and their representations are
mrk(dq) = Zk, er 1Q
QNkr ∈ dq
=
1
2
ς(q)dq + U¯kr.
3301
(12)
(13)
(14)
(15)
To recover the original probability measure P ∈ P(Ω) under which
the model is introduced, consider the following sequence:
γ0 = 1
γk =
2
r=1
2ar(Zk−1, Yk)λrk(Yk, QNr )
k
ς QNr
k
Zk,er
,
k = 1, 2, . . . N.
(16)
4Notice that if the parameter is θ < 0 (resp. θ > 0), then it will create a
situation of risk-seeking (resp. risk-averting) on the part of the optimizer.
Using Girsanov's theorem [27], [29], we can set the RadonNikodym
derivative as
dP = Γ0,kdP¯,
k = 0, 1, . . . , N
(17)
where Γ0,k = lk=1 γl, its restriction is implicitly known to the
complete filtration that is generated by the processes Y , Z, and Q.
This fact is a direct application of Girsanov's theorem [29]. For the
sake of completeness, a short description of this theorem including
the measure transformation (i.e., the construction of this change of
measure for the discrete-time measure valued processes) is given in
the supplementary document.
B. Change of Measure for the Plant Dynamics Variables
For any admissible control sequences u ∈ U0,N−1, consider the
following random variable:
Λ0u,0 = 1
Λ1u,k =
k
l=1
ϕ(xl − Axl−1 − γ(Zl)Bul−1) φ(yl − Cxl−1),
ϕ(xl)φ(yl)
k = 1, 2, . . . , N.
3302
IEEE TRANSACTIONS ON AUTOMATIC CONTROL, VOL. 60, NO. 12, DECEMBER 2015
For a finite-state Markov chain model of (3), the measure valued
process αku(x, q) (i.e., the information state for the discrete-time partially
observed stochastic system in (1)) is determined by the following
parameters Υk(u, QNr ), Θk−1(u) and μk(u) that involve coupled fork
ward recursive relations (e.g., see [12]). With minor abuse of notation,
we consider these parameters as an information-state for the system
ζku(u, q) =
Υk u, QNr , Θk−1(u), μk(u) .
k
(23)
Furthermore, we can rewrite the measure valued process αku(x, q) as
follows:
αku(x, q) = αku (ζku(u, q), x)
= Υk u, QNr exp
k
1
− 2 (x−μk(u))T Θk−1(u)(x−μk(u)) . (24)
C. Solution to Risk-Sensitive Control Problem Under a Markov
Modulated DoS Attack Model
In the following, we further provide a solution for the optimal
control policy in terms of finite-dimensional dynamics, i.e., a separated
policy in terms of the equivalent information-state, using a dynamic
programming technique.
For any admissible control sequences and sample-path of the DoS
attacks, the expected total cost in (2) with respect to the equivalent
probability measure transformation is given as follows:
J (u) =
1 E exp
θ
θ
2
xkT M xk +γ(Zk+1)ukT Suk
N−1
k=0
+ xTN MN xN
(18)
(19)
Using this random variable, we can introduce a new equivalent
measure transformation Pˆ ∈ P(Ω) as follows
dPˆ =
Λ0u,k −1 dP¯,
k = 0, 1, . . . , N.
Under this measure transformation Pˆ, the state xk and the observation
yk will become normal densities and independent to each other.
Moreover, the restriction of the Radon-Nikodym derivative implies the
measure [Λ0u,k]−1 is a martingale process with respect to the complete
filtration (e.g., see [24], [27], [29]). Further, if we combine the above
change of measures, i.e., (17) and (19), then we have following:
dPˆ =
=
Λ0u,k −1 dP¯
Λ0u,k −1 Γ0,kdP,
k = 0, 1, . . . , N.
(20)
Next, consider the following measure valued process for any admissible
control u and DoS attack sequences in the system
αku(x, q)dxdq = Eˆ Λ0u,k Γ0u,k −1 exp θD0u,k−1 1A(xk ∈ dx)
× Zk, er 1Q
QNkr ∈ dq |Y ∨ M
, k = 0, 1, . . . , N
(21)
where 1A(xk ∈ dx) is the indicator function of the Borel set A, Dju,k is
the quadratic running function given by Dju,k = (1/2) lk=j (xlTM xl +
γ(Zl+1)ulT Sul) for 0 ≤ j ≤ k ≤ N − 1. Note that the above expectation
in the right-hand side is performed with respect to Pˆ; and,
moreover, the initial boundary condition for this measure valued
process is given by α0u(x0, q0) = ϕ(x0)ς(q0).
Then, we obtain the following theorem.
Theorem 1: The measure valued process αku(x, q) satisfies the
following forward recursion:
u
αk+1(x, q)dxdq
=
1
φ(yk+1)
B(Rd) B(Rn) r=1
2
Zk+1, er ς(q)
2ar(Zk, Yk+1)λrk+1(Yk+1, q)
× exp θDku,k ϕ x − Aξ − γ(Zk+1)Buk φ(yk+1 − Cξ)
× αku(ξ, τ )dξdτ (22)
where Dku,k = (1/2)(ξT M ξ + γ(Zk+1)ukT Suk).
=
=
=
=
1
θ
1
θ
1
θ
1
θ
1
θ
θ
2
= 1θ Eˆ⎢⎣
⎡
B(Rd) B(Rn)
Eˆ Λ0u,N
u
Γ0,N
−1 exp θD0u,N−1
× exp
xTN MN xN
Eˆ Eˆ Λ0u,N
u
Γ0,N
−1 exp θD0u,N−1
× exp
xTN MN xN |YN ∨ MN
θ
2
θ
2
⎤
xTM x αN (x, q)dxdq⎥ . (25)
⎦
For any k, 0 < k < N the expected total cost can be expressed
equivalently in terms of this information-state as
J (u) =
Eˆ Λ0u,N
u
Γ0,N
−1 exp θD0u,N−1
× exp
xTN MN xN
Eˆ Λ0u,k Γ0u,k −1 [Λku+1,N
u
Γk+1,N
× exp θD0u,k−1 exp θDku,N−1 exp
xTN MN xN
Eˆ Λ0u,k Γ0u,k −1 exp θD0u,k−1
× Eˆ Λku+1,N Γk+1,N
u
−1 exp θDku,N−1
× exp
xTN MN xN |σ{xk} ∨ σ {mrk} ∨ YN ∨ MN
(26)
θ
2
exp
θ
2
−1
θ
2
where the inner expectation involves only conditioning on σ{xk} ∨
σ{mrk} due to the Markov property of xk and mrk. Define a new
adjoint process
ηku(xk, q) = Eˆ Λku+1,N Γk+1,N
u
−1exp θDku,N−1 exp
θ
2
× xTN MN xN |σ{xk} ∨ σ {mrk} ∨ YN ∨ MN . (27)
With this, the expected total cost can be further rewritten as
J (u) =
Eˆ Λ0u,k Γ0u,k −1exp θD0u,k−1 ηku(xk, q)#
IEEE TRANSACTIONS ON AUTOMATIC CONTROL, VOL. 60, NO. 12, DECEMBER 2015
Moreover, the adjoint process ηku is given by the following equivalent
relation [cf. (23) and (24)]:
1
ηku(x, q) = Υ˜k u, QNr exp − 2 (x−μ˜k(u))T Θ˜k−1(u)(x−μ˜k(u))
k
where the finite-dimensional parameters Υ˜k(u, QNr ), Θ˜k−1(u) and
k
μ˜k(u) satisfy coupled backward, recursions. From (22) [and also
equation (A.2) in the supplementary document], the information-state
αku(x, q) is determined by Υk(u, QNr ), Θk−1(u) and μk(u). Thus,
k
based on the current value of ζku together with the new observation
yk+1, current control uk and the sample-path of the DoS attack
sequence γ(Zk+1), the next value for ζku+1 can be determined by the
following functional relation:
which is independent of k.
Theorem 2: The adjoint process ηku(x, q) satisfies the following
backward recursion:
ηku(xk, q) =
2
Zk+1, er ς(q)φ(yk+1 −Cxk)
2ar(Zk+1, Yk+1)λrk+1(Yk+1, q)φ(yk+1)
B(Rd)B(Rn) r=1
× ϕ x−Axk −γ(Zk+1)Buk exp(θDku,k)ηku+1(x, τ)dxdτ.
ζk+1 = ζk+1 ζku, uk, yk+1, mrk+1 .
u u
Suppose at some intermediate time k, 0 < k < N , the informationstate
ζku is given by ζ = (Υ(.), Θ−1(.), μ(.)), then from (28), the
value function for the optimal control problem satisfies the following:
V (ζ, k) =
ess inf Eˆ [ αku, ηku |αk = αk(ζ) ] .
u∈Uk,N−1
where Uk,N−1 is the set of admissible control sequences in the interval
[k, N − 1].
=
=
=
1
θ
1
θ
1
θ
1θ Eˆ⎢⎣
⎡
B(Rd) B(Rn)
Eˆ[ αku(x, q)ηku(x, q) ]
Eˆ Eˆ Λ0u,k Γ0u,k −1exp θD0u,k−1 ηku(xk, q)|YN ∨MN
##
αku(x, q)ηku(x, q)dxdq⎥
⎦
⎤
(28)
(29)
(30)
(31)
(32)
3303
(33)
Theorem 3: The value function satisfies the following recursion
with:
V (ζ, k) = ess inf Eˆ V ζk+1 ζ, u, yk+1, mrk+1 , k + 1
u
u∈Uk,k
with V (ζ, N ) = αN (ζ), ηN (ζ) .
Finally, we remark that the optimal control sequences u∗k(ζk) for
each k = 0, 1, . . . , N − 1 of the dynamic programming problem are
indeed the optimal control policies for the original problem stated in
(11), i.e., u∗ ∈ U0,N−1.
IV. CONCLUDING REMARKS
In this technical note, we considered a finite-horizon risk-sensitive
control problem under a Markov modulated DoS attack model when
the attacker strategy is to disrupt the network or jam the control packets
from reaching the actuator. Using a chain of measure transformation
techniques and dynamic programming, we derived an optimal control
policy in terms of the finite-dimensional dynamics of the system
that satisfies a separation principle, i.e., the recursive optimal control
policy together with the newly defined information state constitute an
equivalent fully observable stochastic control problem. Furthermore,
the solution to the optimal control problem appeared as if it depends
on the average sequences or path of the DoS attack in the system.
REFERENCES
[1] E. Bompard, G. Ciwei, R. Napoli, A. Russo, M. Masera, and A. Stefanini,
“Risk assessment of malicious attacks against power systems,” IEEE
Trans. Syst., Man, Cybern. A, vol. 39, no. 5, pp. 1074-1085, 2009.
[2] G. Ericsson, “Toward a framework for managing information security for
an electric power utility-CIGRE experiences,” IEEE Trans. Power Del.,
vol. 22, no. 3, pp. 1461-1469, 2007.
[3] A. Pinar, J. Meza, V. Donde, and B. Lesieutre, “Optimization strategies for
the vulnerability analysis of the power grid,” SIAM J. Optimiz., vol. 20,
no. 4, pp. 1786-1810, 2010.
[4] A. Teixeira, G. Dan, H. Sandberg, and K. H. Johansson, “A cyber security
study of a SCADA energy management system: Stealthy deception attacks
on the state estimator,” in Proc. 18th IFAC World Congr., Milano, Italy,
2011, pp. 11271-11277.
[5] Y. Liu, P. Ning, and M. K. Reiter, “False data injection attacks against
state estimation in electric power grids,” ACM Trans. Inform. Syst. Secur.,
vol. 14, no. 1, pp. 13:1-13:33, 2011.
[6] S. Amin, A. A. Cardenas, and S. S. Sastry, “Safe and secure networked
control systems under denial-of-service attacks,” in Hybrid Systems:
Computation and Control. Berlin/Heidelberg, Germany: SpringerVerlag,
pp. 31-45, 22009.
[7] A. A. Cardenas, S. Amin, and S. Sastry, “Research challenges for the
security of control systems,” in Proc. 3rd USENIX Workshop on Hot
Topics in Security (HotSec 08), 2008, pp. 1-6.
[8] K. C. Nguyen, T. Alpcan, and T. Basar, “A decentralized Bayesian attack
detection algorithm for network security,” in Proc. 23rd Int. Information
Security Conf., Milan, Italy, 2008, pp. 413-428.
[9] D. R. Raymond and S. F. Midkiff, “Denial-of-service in wireless sensor
networks: Attacks and defenses,” IEEE Perv. Comput., vol. 7, no. 1,
pp. 74-81, 2008.
[10] S. Roy, C. Ellis, S. Shiva, D. Dasgupta, V. Shandilya, and Q. Wu, “A
survey of game theory as applied to network security,” in Proc. 43rd
Hawaii Int. Conf. Systems Science, 2010, pp. 1-10.
[11] S. Weinberger, “Computer security: Is this the start of cyberwarfare?”
Nature, vol. 474, pp. 142-145, 2011.
[12] G. K. Befekadu, V. Gupta, and P. J. Antsaklis, “Risk-sensitive control
under a class of denial-of-service attack models,” in Proc. American
Control Conf., 2011, pp. 643-648.
[13] D. H. Jacobson, “Optimal stochastic linear systems with exponential performance
criteria and their relation to deterministic differential games,”
IEEE Trans. Autom. Control, vol. AC-18, no. 2, pp. 124-131, Apr. 1973.
[14] D. P. Bertsekas, Dynamic Programming and Stochastic Control.
New York, NY, USA: Academic Press, 1976.
[15] P. Whittle, “Risk-sensitive linear/quadratic/Gaussian control,” Adv. Appl.
Probab., vol. 13, no. 4, pp. 764-777, 1981.
3304
IEEE TRANSACTIONS ON AUTOMATIC CONTROL, VOL. 60, NO. 12, DECEMBER 2015
[16] A. Bensoussan and J. H. van Schuppen, “Optimal control of partially observable
stochastic systems with an exponential-of-integral performance
index,” SIAM J. Control Optimiz., vol. 23, pp. 599-613, 1985.
[17] M. R. James, J. Baras, and R. J. Elliott, “Risk-sensitive control and
dynamic games for partially observed discrete-time nonlinear systems,”
IEEE Trans. Autom. Control, vol. 39, no. 4, pp. 780-792, Apr. 1994.
[18] I. I. Petersen, M. R. James, and P. Dupuis, “Optimal control of stochastic
uncertain systems with relative entropy constraints,” IEEE Trans. Autom.
Control, vol. 45, no. 3, pp. 398-412, Mar. 2000.
[19] J. Hespanha, P. Naghshtabrizi, and Y. Xu, “A survey of recent results in
networked control systems,” Proc. IEEE Special Issue on Techn. Netw.
Cont. Syst., vol. 95, no. 1, pp. 138-162, 2007.
[20] D. Liberzon and J. P. Hespanha, “Stabilization of nonlinear systems with
limited information feedback,” IEEE Trans. Autom. Control, vol. 50,
no. 6, pp. 910-915, Jun. 2005.
[21] G. N. Nair, R. J. Evans, I. M. Y. Mareels, and W. Moran, “Topological
feedback entropy and nonlinear stabilization,” IEEE Trans. Autom.
Control, vol. 49, no. 9, pp. 1585-1597, Sep. 2004.
[22] V. Gupta and N. Martins, “On stability in the presence of analog erasure
channels between controller and actuator,” IEEE Trans. Autom. Control,
vol. 55, no. 1, pp. 175-179, Jan. 2010.
[23] L. Schenato, B. Sinopoli, M. Franceschetti, K. Poolla, and S. S. Sastry,
“Foundations of control and estimation over lossy networks,” Proc. IEEE,
vol. 95, no. 1, pp. 163-187, Jan. 2007.
[24] G. B. Di Masi and W. J. Runggaldier, “On measure transformations
for combined filtering and parameter estimation in discrete time,” Syst.
Control Lett., vol. 2, no. 1, pp. 57-62, 1982.
[25] R. J. Elliott, L. Aggoun, and J. B. Moore, Hidden Markov Models:
Estimation and Control. New York, NY, USA: Springer-Verlag, 1995.
[26] G. K. Befekadu, V. Gupta, and P. J. Antsaklis, “Risk-sensitive
control under a Markov modulated denial-of-service attack model,” in
Proc. 50th IEEE Dec. Contr. and Europ. Contr., Orlando, FL, USA,
Dec. 2011, pp. 5714-5719.
[27] R. S. Liptser and A. N. Shiriyayev, Statistics of Random Processes I:
General Theory, vol. 1. New York, NY, USA: Springer-Verlag, 1977.
[28] M. Papa, S. Shenoi, T. Fleury, H. Khurana, and V. Welch, “Towards
a taxonomy of attacks against energy control systems,” in
Critical Infrastructure Protection II. Boston, MA, USA: Springer, 2009,
pp. 71-85.
[29] I. V. Girsanov, “On transforming a certain class of stochastic processes by
absolutely continuous substitution of measures,” Theor. Probabil. Appl.,
vol. 5, no. 3, pp. 285-301, 1960.