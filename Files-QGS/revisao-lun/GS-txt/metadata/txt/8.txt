A Markovian Approach for Attack Resilient Control of Mobile Robotic Systems. In this paper we propose an optimal planning strategy against malicious attacks on stochastic robotic cyber-physical systems (CPS). By injecting erroneous information and compromising sensor data, an attacker can hijack a system driving it to unsafe states. In this work we bear on the problem of choosing optimal actions while one or more sensors are not reliable. We assume that the system is fully observable and at least one measurement (however unknown) returns a correct estimate of a state. We build an algorithm that leverages the theory of Markov Decision Processes (MDPs) to determine the optimal policy to plan the motion of unmanned vehicles and avoid unsafe regions of a state space. We identify a new class of Markovian processes, which we call Redundant Observable MDPs (ROMDPs), that allows us to model the effects of redundant attacked measurements. A quadrotor case study is introduced and simulation and experimental results are presented to validate the proposed strategy. 
