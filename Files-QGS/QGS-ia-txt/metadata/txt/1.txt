Title: A comparison of automated training-by-example selection algorithms for
Evidence Based Software Engineering

Keywords: Research infrastructure, Evidence Based Software Engineering, Systematic Literature Review, Systematic Mapping Studies, Culling, VSM, LSA, Recall, Precision, Document selection


Abstract: 

Context: Study search and selection is central to conducting Evidence Based Software Engineering (EBSE) research, including Systematic Literature Reviews and Systematic Mapping Studies. Thus, selecting relevant studies and excluding irrelevant studies, is critical. Prior research argues that study selection is subject to researcher bias, and the time required to review and select relevant articles is a target for optimization.
Objective: This research proposes two training-by-example classiﬁers that are computationally simple, do not require extensive training or tuning, ensure inclusion/exclusion consistency, and reduce researcher study selection time: one based on Vector Space Models (VSM), and a second based on Latent Semantic Analysis (LSA).

Method: Algorithm evaluation is accomplished through Monte-Carlo Cross-Validation simulations, in which study subsets are randomly chosen from the corpus for training, with the remainder classiﬁed by the algorithm. The classiﬁcation results are then assessed for recall (a measure of completeness), precision (a measure of exactness) and researcher eﬃciency savings (reduced proportion of corpus studies requiring manual review as a result of algorithm use). A second smaller simulation is conducted for external validation.

Results and conclusions: VSM algorithms perform better in recall; LSA algorithms perform better in precision. Recall improves with larger training sets with a higher proportion of truly relevant studies. Precision improves with training sets with a higher portion of irrelevant studies, without a signiﬁcant impact from the training set size. The algorithms reduce the inﬂuence of researcher bias and are found to signiﬁcantly improve researcher eﬃciency. To improve recall, the ﬁndings recommend VSM and a large training set including as many truly relevant studies as possible. If precision and eﬃciency are most critical, the ﬁndings suggest LSA and a training set including a large proportion of truly irrelevant studies.
